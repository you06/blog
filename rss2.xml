<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Freezing</title>
    <link>https://blog.tongmu.me/</link>
    
    <image>
      <url>https://blog.tongmu.me/icon/icon.png</url>
      <title>Freezing</title>
      <link>https://blog.tongmu.me/</link>
    </image>
    
    <atom:link href="https://blog.tongmu.me/rss2.xml" rel="self" type="application/rss+xml"/>
    <atom:link href="https://blog.tongmu.me/" rel="hub"/>
    <description>you06&#39;s blog &amp; everything</description>
    <pubDate>Wed, 14 Feb 2024 15:21:24 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>风景摄影-2024-01</title>
      <link>https://blog.tongmu.me/2024/02/15/photography-2024-02/</link>
      <guid>https://blog.tongmu.me/2024/02/15/photography-2024-02/</guid>
      <pubDate>Thu, 15 Feb 2024 01:10:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="仙台青叶山"><a href="#仙台青叶山" class="headerlink" title="仙台青叶山"></a>仙台青叶山</h2><p>从青叶山上看仙台城，还可以看到远处的海平面。</p><ul><li>200mm</li><li>f/5.6</li></ul><p><img src="./sendai-city.jpg" alt="sendai-city"></p><hr><h2 id="日本三景-松岛"><a href="#日本三景-松岛" class="headerlink" title="日本三景 - 松岛"></a>日本三景 - 松岛</h2><h3 id="双子岛"><a href="#双子岛" class="headerlink" title="双子岛"></a>双子岛</h3><ul><li>87mm</li><li>f/5.6</li></ul><p><img src="./matsushima-godaido.jpg" alt="matsushima-godaido"></p><h3 id="钟岛"><a href="#钟岛" class="headerlink" title="钟岛"></a>钟岛</h3><ul><li>200mm</li><li>f/5.6</li></ul><p><img src="./matsushima-kanejima.jpg" alt="matsushima-kanejima"></p><h3 id="不知名岛屿-1"><a href="#不知名岛屿-1" class="headerlink" title="不知名岛屿 1"></a>不知名岛屿 1</h3><ul><li>200mm</li><li>f/5.6</li></ul><p><img src="./matsushima-3.jpg" alt="matsushima-3"></p><h3 id="不知名岛屿-2"><a href="#不知名岛屿-2" class="headerlink" title="不知名岛屿 2"></a>不知名岛屿 2</h3><ul><li>200mm</li><li>f/5.6</li></ul><p><img src="./matsushima-4.jpg" alt="matsushima-4"></p><h3 id="海边蓝房子"><a href="#海边蓝房子" class="headerlink" title="海边蓝房子"></a>海边蓝房子</h3><ul><li>200mm</li><li>f/5.6</li></ul><p><img src="./matsushima-blue-house.jpg" alt="matsushima-blue-house"></p><hr><h2 id="仙台大观音"><a href="#仙台大观音" class="headerlink" title="仙台大观音"></a>仙台大观音</h2><ul><li>156mm</li><li>f/7.1</li></ul><p><img src="./sendai-daikannon-street.jpg" alt="sendai-daikannon-street"></p>]]></content:encoded>
      
      
      
      
      <comments>https://blog.tongmu.me/2024/02/15/photography-2024-02/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>2023 年游戏清单</title>
      <link>https://blog.tongmu.me/2024/02/14/gamelist-2023/</link>
      <guid>https://blog.tongmu.me/2024/02/14/gamelist-2023/</guid>
      <pubDate>Wed, 14 Feb 2024 15:21:24 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>今年退出了大坑 MapleStory（冒冒），终于有时间可以玩一玩单机了，之前还在冒冒的时候不练级每天也要花半到一个小时在日常上，而且不像手游可以利用通勤等琐碎的时间，实在是让人又爱又恨。</p><p>这次回坑冒冒大概玩了两年，最后的进度停在了解锁创世武器并且击败 <a href="https://maplestory.fandom.com/wiki/Seren/Monster">Seren</a>。因为遇到了好多真心对待游戏的朋友，我攻略 boss 的时候总是有伙伴的帮助，感谢感谢。</p><p>冒冒把练级作为核心玩法之一，确实是劝退普通玩家的主要原因，但是优秀的音乐和设定基础，又让 90 年代的愿意为他付出时间，我一律劝退对这个游戏感兴趣的人，如果你真的是它的受众，那么再怎么劝退也没有用。</p><p>我们团队第一次过黑魔法师的记录：<a href="https://www.bilibili.com/video/BV17W4y167AM/">https://www.bilibili.com/video/BV17W4y167AM/</a></p><p>那么接下来就盘点今年玩的其他游戏：</p><h2 id="空の軌跡-FC-amp-SC"><a href="#空の軌跡-FC-amp-SC" class="headerlink" title="空の軌跡 FC&amp;SC"></a>空の軌跡 FC&amp;SC</h2><p>战斗系统比较单调，还遇到过几次闪退/卡死导致进度丢失的情况（没有自动存档），但是不错的剧情和音乐，奠定了轨迹系列的优秀基础，没有玩 3rd 有几个原因，一是小艾和小约的故事就像完成了一个章节一样，看到这里已经对他们的未来有所担心，二是没有这么喜欢神父这个角色（实际在 SC 中也没怎么使用他），Steam 上的版本打语言补丁麻烦而且可能会遇到 bug。</p><p>旅行不是 from A to B，如果闷头走主线的话，会错过很多有趣的故事。</p><h2 id="ペルソナ5スクランブル-P5S"><a href="#ペルソナ5スクランブル-P5S" class="headerlink" title="ペルソナ5スクランブル(P5S)"></a>ペルソナ5スクランブル(P5S)</h2><p>上手之后战斗手感还不错，可以无限进出监狱补血导致甩技能流玩的很爽，主角团走出东京知乎带你来了一场日本环游，本来对东北毫无兴趣的，现在觉得得去仙台吃一趟牛舌了。<br>个人感觉游戏后期的节奏比较快，而对于玩过 P5 本体的玩家这个剧情太熟悉了，像是把样板戏又演了一遍。</p><p>如果没有本体的加持，P5S 是很一般的，但是老角色再登场以及保留了庞大的面具系统，让这个游戏玩起来非常有趣。</p><h2 id="eden"><a href="#eden" class="headerlink" title="eden*"></a>eden*</h2><p>游戏很短，虽然是 sad story，但是我并没有对结局难以接受，minori 营造了一个让人平静的游戏环境，让玩家接受随星球一起离去。游戏没有过多渲染シオン的悲剧情节，通过世外桃源让玩家想象权力控制的恐惧。<br>故事中的角色都将自身的情感摆在了比权力命令更高的位置上，深表赞同。</p><h2 id="CRISIS-CORE-FINAL-FANTASY-VII-REUNION"><a href="#CRISIS-CORE-FINAL-FANTASY-VII-REUNION" class="headerlink" title="CRISIS CORE -FINAL FANTASY VII- REUNION"></a>CRISIS CORE -FINAL FANTASY VII- REUNION</h2><p>作为前传登场的重制版篇章，ザックス的老虎机系统提供了各种奇怪的技能和续航，战斗的爽快感很不错。<br>这作怪物使用蓄力大招的时候需要通过累计伤害来削减大招对自己造成的伤害，如果怪物在你的长后摇时使用蓄力大招，就会造成没有时间去打累计伤害，吃到 100% 大招的情况（可能直接暴毙），以及在手上捏有大招和没有大招的时候打断能力差别太大，这个点不是很爽。</p><p>在第一部重制版中，克劳德一直是团队作战，而ザックス则没有那么多好队友，战斗都是和怪物的单挑，玩起来还是挺寂寞的。</p><p>最后游戏流程太短了，我感觉自己也算慢慢打的类型了，结果不到 20h 就通关了。那些要摸完所有宝箱的支线任务，暗雷遇怪，有的地图宝箱藏的很隐蔽还挺折磨人的，实在是没有耐心做完…</p><h2 id="Monster-Hunter-Rise-Sun-Break"><a href="#Monster-Hunter-Rise-Sun-Break" class="headerlink" title="Monster Hunter Rise Sun Break"></a>Monster Hunter Rise Sun Break</h2><p>只有认真玩怪猎了，才能感受到这个游戏庞大的战斗系统，一个武器不玩几百小时都不好意思说自己会了，目前怪猎有十四种武器，真是多少时间都不够玩的。</p><p>除了方便和朋友联机，switch 玩起来还是不太爽的，虽然卡婊优化已经很不错了，炎火村快速移动的速度很棒，但是进图加载和某些场景的掉帧还是令人无奈。</p><p>建议少看大佬速刷，那都是打过不知道多少次之后，对怪物的行动逻辑和伤害判定了如指掌的结果，对比自己重复被撞飞喝药就会有很强的失落感，反正我是用不好最强的大剑，根本打不到怪，玩玩轻弩重弩爽了就挺好的。</p><h2 id="サクラの刻"><a href="#サクラの刻" class="headerlink" title="サクラの刻"></a>サクラの刻</h2><p>作为最期待的续作之一，结果令人不太满意。<br>明明有很多新角色登场，最后变成了老角色返场秀，续作应该有新的故事，而不是后日谈般的讲些理所应当的事，在有前作音乐剧情的加持下，如此新作是不尽人意的。</p><p>本作在结尾还挖了个坑，还要做一部サクラノ響，希望可以看到新的故事，比较关注的是是否会是女性主角。</p><h2 id="ポケットモンスター-スカーレット"><a href="#ポケットモンスター-スカーレット" class="headerlink" title="ポケットモンスター スカーレット"></a>ポケットモンスター スカーレット</h2><p>这次的宝可梦朱紫比前作剑盾好玩的多，自由的探索顺序，简化了那套古董养成系统，不错的剧情，优秀的太晶化系统，删除了暗雷系统。可以说只要你对宝可梦有一点兴趣，这作朱紫就能让你爽玩。</p><p>但是 GF 的技术力，导致朱紫没有做到 100 分，游戏可以优化的地方非常多，而且看起来也不像是这个年代的画面，有一些影响心情的小 bug。</p><h2 id="Diablo-IV"><a href="#Diablo-IV" class="headerlink" title="Diablo IV"></a>Diablo IV</h2><p>我是第一次接触以“刷”为核心玩法的游戏，刷了一个赛季其实还挺好玩的，当你改了一套配装、巅峰和技能之后，刷怪如游泳的感觉很爽。</p><p>刷子游戏如果不能爽，就只剩坐牢了，所以不要强迫自己去玩弱势套路，就得玩版本之子。</p><p>晒一张令我满意的装备吧。</p><p><img src="diablo-iv-equip.png" alt="我的手套"></p><h2 id="ゼノブレイド2"><a href="#ゼノブレイド2" class="headerlink" title="ゼノブレイド2"></a>ゼノブレイド2</h2><p>我玩异度之刃的顺序是 3-&gt;1-&gt;2，其中 2 和 3 的战斗系统都很棒，玩了 2 之后，对于 3 能够如此大改战斗系统非常满意。1 的战斗系统就比较弱了，所以我只是当故事来看。<br>在打 2 之前玩了 1 还是对理解剧情有不少帮助的。从剧情深度上来说，2 可能是三作里最高的，可以说是 JRPG 的典范了，战斗系统没有用简单的回合制来敷衍了事。</p><p>JRPG 在讲述了一个很棒的故事之后，往往会发现所有的角色都是令人喜爱的，出于想要看到更多故事的想法，就会对游戏结束的太早感到可惜。</p>]]></content:encoded>
      
      
      
      <category domain="https://blog.tongmu.me/tags/%E6%B8%B8%E6%88%8F/">游戏</category>
      
      
      <comments>https://blog.tongmu.me/2024/02/14/gamelist-2023/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>PolarDB-SCC 笔记</title>
      <link>https://blog.tongmu.me/2023/09/16/PolarDB-SCC-notes/</link>
      <guid>https://blog.tongmu.me/2023/09/16/PolarDB-SCC-notes/</guid>
      <pubDate>Sat, 16 Sep 2023 18:15:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>PolarDB 在 VLDB 2023 又发了篇文章，讲他们是如果做一个 SCC(Strongly Consistent Cluster) 的，这篇文章标题很大，但核心内容缺不大，也属于瞄准一小点所做的工作。文章称他们的工作是 “first ’read-write splitting’ cloud-native database”，这点请读者自行品味，本文仅仅讲一下我所看到的亮点。</p><h2 id="目标问题"><a href="#目标问题" class="headerlink" title="目标问题"></a>目标问题</h2><p>这篇文章要解决的目标问题比较简单，在一写（RW）多读（RO）的集群并且需要 read-after-write consistency 时，往往需要 RW 节点来处理许多读请求，而这一架构原本的目标是将读请求都 offload 到 RO 节点上面去，现实中由于 read-after-write 的要求，目标没有达到，figure 2 可以看到在读流量增长时，RW 节点的 CPU 也跟着增长，RO 节点确实一核有难，八核围观。</p><p><img src="./1.png" alt="1"></p><p>为了达成原本的设计目标，即即使在 read-after-write 的要求下，也能够讲读请求 offload 到 RO 节点上，论文设计了 PolarDB-SCC。</p><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>现有的在 RO 节点上做到 read-after-write 的方法有两种 commit-wait 和 read-wait，但都有缺陷。</p><ul><li>commit-wait 等所有读节点都同步完之后才返回 commit 成功，写入延迟无法接受</li><li>read-wait 需要等 RO 的 buffer 进度跟上 RW 才能处理读请求，读取延迟无法接受</li></ul><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>PolarDB-SCC 的解法很直接，使用 read-wait 策略，但是将 buffer 切分，切分后，只要是 buffer 没有变化的分片，就不需要 wait。</p><h2 id="Design"><a href="#Design" class="headerlink" title="Design"></a>Design</h2><p>PolarDB-SCC 有三部分工作</p><ul><li>Hierarchical modification tracker</li><li>Lamport timestamp</li><li>RDMA-based log shipping protocol（与核心思想关系不大）</li></ul><h3 id="Hierarchical-modification-tracker"><a href="#Hierarchical-modification-tracker" class="headerlink" title="Hierarchical modification tracker"></a>Hierarchical modification tracker</h3><p>这部分分为了 global，table，page 三层，分别记载了自己的 scope 下的 max modification timestamp，当遇到读请求时，从 global 检查到 page，只要 <code>read timestamp &gt; level max modification timestamp</code>，读请求就可以直接进行，不需要 read wait，只有当 <code>read timestamp &lt;= page max modification timestamp</code>，才需要 read wait。</p><p>Max modification timestamp 的检查是 RO 发起的，但是 herarchical modification tracker 却在 RW 之上，如果每次都去 RW 上读一下，那 overhead 会很大，所以下面就来解决 overhead 的问题。</p><h3 id="Linear-Lamport-timestamp"><a href="#Linear-Lamport-timestamp" class="headerlink" title="Linear Lamport timestamp"></a>Linear Lamport timestamp</h3><p>其实 Lamport timestamp 不是减少拿 max modification timestamp 的关键，关键是它有一个 batch 机制。如果一个 read request 开始处理时，没有空 connection，那么它会被加入队列，等待 available connection，available connection 会取一个当前的 max modification timestamp，用它来检测所有队列中的 read request 是否可以跳过 read wait。</p><p>此外，RO 节点还会做一个 cache，如果后面来的 read request timestamp 比 cached RO timestamp 更小，则直接使用 cache 值。</p><p>如果是 repeatable read 的 isolation，那只需要用 begin 时候的 timestamp 来做检测就好了，后面的一定会命中 cache。哈哈，又发现又一个 RR 比 RC 实现简单的例子。</p><p><img src="./2.png" alt="2"></p><p>另外上面提到了分层嘛，如果需要检测多层的话，实践中会分多次去 RW 节点 fetch max timestamp。</p><p>进一步的，为了降低 timestamp fetching 对 RW 节点的影响，这里使用了 one-sided RDMA，可以避免 RW 节点的 CPU 介入。而上面的分层 timestamp 使用 hash 也是为了能够提前确定 RDMA fetch 的地址。</p><h3 id="RDMA-based-log-shipping-protocol"><a href="#RDMA-based-log-shipping-protocol" class="headerlink" title="RDMA-based log shipping protocol"></a>RDMA-based log shipping protocol</h3><p>这个感觉和文章的核心思想关系不大，在有 RDMA 的情况下，文章又想着用 RDMA 来同步 log，但是 buffer ring 会被反复刷写（RW 节点无法感知 RO 节点的 apply 进度），所以需要仔细检查 buffer 合法性，在 buffer ring 被刷掉时，RO 节点就需要去 storage node 读取 log。</p><p>在最后的 review 中，文章提到这个优化只起到了 4% 的效果，因为在能够跳过 read wait 之后，apply duration 不再是瓶颈（只有少部分需要等 read wait 的 read request 收益于这个优化）。</p><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><p>文章还做了一个优化，因为同一个事务需要读到自己所写入的数据，在 RW 节点处理完写入语句后，会给 proxy 节点返回一个 LSN，在处理后续的读语句时，proxy 节点会尽可能选择满足这个 LSN 的 RO 节点，算是一个小小的优化。</p><h2 id="Challenge"><a href="#Challenge" class="headerlink" title="Challenge"></a>Challenge</h2><p>看这篇文章的时候唤醒了我对 PolarDB-X 的一些疑问，通常我们都是先看市场需求之后再考虑数据库的设计，而 PolarDB-SCC 的做法，将 RW 和 RO 节点绑定在了同一个数据中心，他们通过 RDMA 相连，速度非常快。但是这样的大集群能否抗住 AZ outage，是否会在实践中产生很多的跨 AZ 流量？换言之，追求一个 AZ 内部的性能是不是市场真正的需求？</p>]]></content:encoded>
      
      
      
      
      <comments>https://blog.tongmu.me/2023/09/16/PolarDB-SCC-notes/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>PolarDB-X 笔记</title>
      <link>https://blog.tongmu.me/2023/06/18/PolarDB-X-notes/</link>
      <guid>https://blog.tongmu.me/2023/06/18/PolarDB-X-notes/</guid>
      <pubDate>Sun, 18 Jun 2023 15:53:53 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>这篇文章密密麻麻列了二十来个作者，一看就是厨艺界的米其林，DB 界的国家队，让我看看到底做了些啥。</p><h2 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h2><p>虽然在大公司里开坑似乎不需要严谨的理由，大家总是可以装模做样的造些需求，但我们还是来看看文章说的需求有没有亮点。</p><ul><li>multi-datacenter deployment，容灾的要求</li><li>the separation of computation and storage，更快的 scale up 速度，也是降低成本的一部分</li><li>利用 HTAP 降本增效</li></ul><p><img src="./1.png" alt="1"></p><p>对于存算分离，论文用双 11 的流量作为例子，在流量上升 122 倍时仍然能够维持稳定的延迟，但是传统数据库想要做到这一点就需要提前扩容到百倍规模，在这种场景下，即使是提前数周也会造成巨大的资源浪费，那么云数据库能做到多少时间完成扩容呢？</p><p>每一个数据库都有一统天下的 HTAP 梦，我泼辣人岂是咸鱼，在阿里云原生的加持下，HTAP 志在必得。</p><h2 id="How"><a href="#How" class="headerlink" title="How"></a>How</h2><p>在这个年代做数据库就像烧菜，你不必从研究野生的香辛料或是如何种地畜牧开始，只需要购买合适的食材，用正确的工序，做出符合顾客口味的菜肴来即可获得大厨的美誉。一起来看看顶级厨师团队的选择。</p><ul><li>HLC-SI，TSO 会产生跨 data center 的延迟，这会使得延迟升高，吞吐降低。我觉得延迟升高可以理解，但是为什么会吞吐降低，这点延迟不是资源使用带来的，因此只要加并发，就可以获得一样的吞吐。除非这是一个有冲突的 workload，会产生等锁排队的情况。</li><li>云原生的弹性，只需要分钟级的时间就可以增加一个 read only 节点，write 节点呢？为了更好的弹性，PolarDB-X 还做了 multi tanent，看起来 multi tanent 和 read/write nodes 是正交的？为什么不给 tanent 绑定 nodes 呢？PolarDB-X 的弹性有多好，文章给了一个例子，160M 行共 40GB 的数据翻倍用了 4-5 秒，这个说法比较抽象，因为他并没有说 node 的数量，并且 40GB 过于小了。我们一般认为扩容只是增加了存储容量上限而不改变实际的数据，如果只是增加一下存储的容量，那似乎不是一件难事。</li><li>HTAP，PolarDB-X 的优化器根据代价判断这是一个 TP 查询还是一个 AP 查询，实际上这里的难点是维护准确的统计信息以保证代价的准确度，但是统计信息维护这种细节就像 “加入少许 MSG” 一样属于行业秘密。PolarDB-X 用一个单独的线程池来执行 AP 查询，并且为他们设置 quota，反正不要让 TP 查询等 CPU 等太久就成。</li></ul><p>大厨做菜当然从前菜到甜点一个不落，说架构之前，我们先来报菜名：</p><ul><li>Global Meta Service (GMS)，存了数据之外的所有东西，负责调度</li><li>Load Balancer，提供一个接入点，就近转发 SQL</li><li>Computation Node (CN)</li><li>Database Node (DN)</li><li>Storage Node (SN)</li></ul><p>看我们的大餐多丰富，隔壁 G 家天天喂 BigTable 是不是已经吃腻了。</p><p><img src="./2.png" alt="2"></p><p>看架构和隔壁铁 DB 还蛮像的 🐶。</p><p>不过架构图也就随便一糊，更重要的是里面的每个节点承担了什么功能，如果某个性能受限的地方背负了它不能承受的负载，那整个系统就会出现瓶颈。</p><h3 id="GMS"><a href="#GMS" class="headerlink" title="GMS"></a>GMS</h3><blockquote><p>It manages the system’s metadata, such as cluster membership, catalog tables, table/index partition rules, locations of shards, and statistics.</p></blockquote><p>我感觉这个设计是图省事，把所有的东西都往 GMS 里面丢，试想一下 GMS 能不能管理一百万张表的信息？如果 GMS 的定位和 etcd 类似，那是很容易遇到性能瓶颈的。</p><h3 id="Load-Balancer"><a href="#Load-Balancer" class="headerlink" title="Load Balancer"></a>Load Balancer</h3><p>就近转发是很正常的思路。看到这里我有个问题是这里的 Load Balancer 是否能够配合 CN 完成平滑升级？比如 DC1 的 Load Balancer 下面有 3 个 CN，在升级 CN 重启进程的时候，连接必然会断开，这里最好能做到：</p><ol><li>在连接待升级的 CN 的事务结束后将后续 SQL 转发到同 DC 的其他 CN</li><li>在待升级的 CN 上的连接全部被驱逐后重启</li><li>所有 CN 滚动升级</li></ol><p>把这些做了，这个 Load Balancer 才能称得上 cloud native。</p><p>如果还有什么可以做，那我想这个 Load Balancer 能不能把 timestamp 给分配了，这样在一个 DC 内至少是有类似 TSO 的效果的。</p><h3 id="Computation-Node"><a href="#Computation-Node" class="headerlink" title="Computation Node"></a>Computation Node</h3><p>CN 里面有 distributed transaction coordinator，parser，cost-based 优化器和执行器，这些都是很常规的配置，但是把优化器的 cost 做准确却不容易。</p><p>听起来 CN 是几乎没有状态的，那么 CN 层的扩展会非常容易。</p><h3 id="Database-Node"><a href="#Database-Node" class="headerlink" title="Database Node"></a>Database Node</h3><p>既然实际的数据还是存储在 SN 上，那为什么还需要 DN 这一层？我感觉是有些历史原因，原本的PolarDB 是一写多读的架构，这里的 DN 就是原本的 PolarDB，里面能有一个 RW 节点和多个 RO 节点。相比于 RDS 的优势里，write scale 是决定性的一点，增加 DN 的数量就可以 write scale，而增加一个 DN 中 RO 节点的数量就能够提供更多的读资源并且不影响 RW 节点。</p><h3 id="Storage-Node"><a href="#Storage-Node" class="headerlink" title="Storage Node"></a>Storage Node</h3><p>其实就是 PolarFS 啦，他有几个特点：</p><ul><li>持久化</li><li>原子性</li><li>水平扩展</li></ul><p>一个 SN 下面可以挂一个 volumn，最大容量 100T，可以以 10GB 为单位扩缩容。能挂到 100T 的容量这点很强，和 <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html#vol-type-ssd">EBS</a> 比较一下，如果没有 io2 express，单 volumn 只能扩展到 16T，但是 io2 可以以 4GB 为单位扩算是一点数据库用不上的优势。这里的好处是如果你的数据很多，但是计算量很少，PolarDB 可以一个 SN 挂 100T，EBS 用户需要 7 个节点才能挂 100T，如果实际上不需要 7 个节点的计算资源，那就是浪费了。</p><blockquote><p>Each chunk has three replicas in each datacenter and linear serializable is guaranteed through Parallel Raft, which is a consensus protocol derived from Raft.</p></blockquote><p>DN 这层已经复制了一次了，FS 层还要复制一下，上面用 Paxos，这里用 Raft，什么杂技团。再回想一下 BigTable，那是真简单粗暴，往里面写就行，可靠性是 BigTable 的事。</p><h3 id="Misc"><a href="#Misc" class="headerlink" title="Misc"></a>Misc</h3><h4 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h4><p>这个问题比较重要，在 auto increment 的 key 上我们经常遇到热点问题，但是 PolarDB-X 把 unique key 都做了 hash partition，这样 bulk insert 不会产生热点，但是代价就是 range scan 的时候要扫多个分区。</p><p>为了减少分布式事务，global/local index 和 clustered/non-clustered index 都做了，用户你看着选吧嘿嘿。</p><p>分布式读写都是个很讨厌的东西，因为延迟一定高，当一个事务涉及到多表时，我们也想尽可能的不要产生分布式读写，PolarDB-X 用 table group 让多个表使用同样的 partition 规则，这样就有机会在多表操作时依旧能够本地搞定。比如原本涉及到两个 shards 的写就会变成分布式事务，涉及到两个 shards 的读就只能在 CN 上 join。</p><h4 id="RW-与-RO-一致性"><a href="#RW-与-RO-一致性" class="headerlink" title="RW 与 RO 一致性"></a>RW 与 RO 一致性</h4><p>在 DN 中，当一个 RW 节点不能够提供足够的读能力时，就需要增加 RO 节点，RO 节点的数量没有明确的限制。</p><p>RW 和 RO 都是从 SN(FS) 中读取数据，所以需要同步的就是 redo log 中还未刷到 SN 里的东西，换一种说法，RW 节点的 redo log 被存在他自己的 buffer pool 里，这部分要同步给 RO 节点，RO 节点才能正确的 serve 读请求。这个问题不难，RW 节点需要等对应的 LSN 被同步到所有 RO 节点后才能够提交事务。</p><h3 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h3><p>PolarDB-X 说他们在 DN 之间用 Paxos 来同步，其中加入了一个叫 Logger 的角色，只复制日志但是不回放，也不会成为 Leader。</p><blockquote><p>Unlike in Aurora, to achieve extremely low storage I/O latency (via RDMA), our cross-datacenter data replication is not achieved at the SN layer, but at the DN layer.</p></blockquote><p>为了降低延迟，复制不放在 SN 层来做，放在 DN 层，这里我感觉和延迟无关，复制本身的延迟在哪都是一样的，但是放在 DN 来做方便处理 redo log（SN 只是个 FS 不知道啥是 log）。另一种猜想是PolarFS 在产品上不支持这种跨 DC 复制的需求，只能放在 DN 里做。</p><p>另外与 Raft 不同，PolarDB 支持异步 commit，是正统 Paxos。为了降低延迟排队，做了 pipeline 和 batch。做了异步 commit 和 pipeline 的代价就是恢复的时候会比较麻烦，在切 leader 时旧 leader 需要清理掉已经 apply 的脏页。我觉得这部分挺重要的，但是文章没有讲的很详细。</p><h3 id="Transaction"><a href="#Transaction" class="headerlink" title="Transaction"></a>Transaction</h3><p>单点授时的 TSO-SI 可以提供严格单调递增的 timestamp，但是有两个潜在问题：</p><ul><li>单点 failure，为了性能，分配 timestamp 的 node 肯定是需要有 leader lease 的，TiDB 的 PD 的 lease 默认是 2s，也就是说，在分配 timestamp 的 node 掉线后，最多需要 2s 才能够选出新的 leader 来继续分配后续的 timestamp。</li><li>单点的性能瓶颈，这是可以通过一次申请多个 timestamp 来优化的，但确实是一个理论上的瓶颈点。</li></ul><p>PolarDB-X 使用了 HLC，其中有 16 位的逻辑位，也就是每毫秒 65535 的吞吐。</p><blockquote><p>Each node in the cluster has a local physical clock $node.pt$ in millisecond, and also maintains its own HLC timestamp $node.hlc$.</p></blockquote><p>我觉得一个 DC 用一个 HLC 更加好，这样保证 DC 内部的 timestamp 是单调递增的，也减少很多 uncertain windows。</p><p>回到 PolarDB-X 的 HLC，它还提到了一些优化方法，在 HLC 的论文中，当物理时间相等时，是需要将逻辑时间 +1 的（如下图），但是这样会浪费 16 位的逻辑时间，所以泼辣DB-X 不加了，接受更多的重复 ts。</p><p><img src="./3.png" alt="3"></p><p>另外如果尝试频繁的用 piggyback 的 ts 来校准自己的时间，固然会使得时间更准确，但也会有性能问题，即使是个原子变量，频繁的进行 CAS 操作也不好的，最坏的情况下可能让缓存失效。为了解决这个问题，PolarDB-X 会减少 update 的次数，例如在分布式事务中只对返回的最大的 ts 去 update。</p><blockquote><p>When the participant encounters a transaction in PREPARED state that modifies the data in its read set, it needs to wait for the transaction to complete.</p></blockquote><p>如果这个事务的 commit 特别慢，一直等着不是一个好策略，理论上可以通过检查事务状态来判断是应该忽略这个 PREPARED 记录还是读到它。</p><p><img src="./4.png" alt="4"></p><p>事务提交是熟悉的两阶段，commit_ts 是选择了 max{prepare_ts}。对于 SI 特性，论文里给了个很简单的证明（单 DN 读），对于跨 DN 读的情况，因为读事务的 snapshot_ts 也会推进 DN 的 HLC，并且它一定和 commit_ts 有严格的大小关系，所以也是成立的。</p><p>这里还有一个遗留问题，我们之前提到了 DN 内是可以一写多读来提升读能力的，如何同步 RW 节点和 RO 节点之间的 HLC 时间？如果读事务推高了 RO 节点的 HLC 却没有管 RW 节点的，那么写事务在 RW 节点上进行的时候就可能使用一个更小的 timestamp，导致 SI 被破坏。一个简单的想法是 HLC 全部由 RW 节点来管理，并且 RW 节点负责转发 RO 节点的请求。</p><h3 id="Multi-Tenancy"><a href="#Multi-Tenancy" class="headerlink" title="Multi Tenancy"></a>Multi Tenancy</h3><p>这种架构复杂的数据库有一个问题就是初始集群需要的节点就很多，十多个节点是基本规模，每个节点的配置还不能差，你要是整个 2c4g 的机器跑，长尾能上天。这样一来，所谓的分布式数据库不就曲高和寡了嘛，所以不得不搞多租户。</p><p>一个 DN 内是单写的，但是租户之间的隔离使得不同的租户可以用不同的 RW 节点，消除写入瓶颈。在实践中，为了支持跨租户事务，会将租户绑定在某个 RW 上，在同一个 RW 上的租户直接的跨租户事务是安全的。但是提供友好的用户接口会比较难，因为对于用户，DN 和 RW 都是隐藏概念，每个 DN 内都有多个 RW 节点，比如 DN1 里有 RW1 和 RW2，DN2 里有 RW3-5，这时候想要绑定 RW1 和 RW3 该如何操作？</p><p>因为有一个强约束是 tenant 只能帮顶一个 RW，所以要切换的时候，需要暂停业务，等旧 RW 上的 DML/DDL 结束，才能把查询往新 RW 发，如果这里面有个大事务或者大 DDL 感觉挺糟糕的，喵喵喵？</p><h3 id="HTAP"><a href="#HTAP" class="headerlink" title="HTAP"></a>HTAP</h3><p>在 PolarDB-X 里，TP 和 AP 查询是共用一个接入点的（共用 CN），CN 节点根据执行代价的估算结果判断这是一个 TP 查询还是 AP 查询，</p><p>对于稍微大些的查询，如果把结果都拿回 CN 节点来算会消耗大量的带宽，因此 PolarDB-X 也做了下推，虽然它说能推到 “storage node”，但是 SN 是 FS 层，究竟有多少计算能力，实现了多少算子其实是个问题。</p><p>资源隔离做得不好的话，一个大 AP 查询能让所有的 TP 业务都超时，论文比较详细的说了他们是怎么做隔离的：</p><ul><li>TP 线程没有资源限制</li><li>AP 线程用 cgroups 限制总时间</li><li>分了几个线程池：TP Core Pool, AP Core Pool, Slow Query AP Core Pool<ul><li>这里根据名字来理解一下就行了</li><li>如果一个 TP 查询很慢，他可能是被误判成 TP 类别的，会把它放到 AP Core Pool 中去</li><li>不看名字可以理解为优先级递减的三个线程池</li></ul></li><li>内存分为四部分管理，一个细节是 TP 能占用 AP 的内存直到查询结束，但是 AP 需要立即释放占用的 TP 内存（当 TP 需要时），这也是保护 TP 业务的手段之一。</li></ul><p>在维护列索引的时候，他们用了一种延迟更新的方案，也就是 AP 的查询不是真正的 realtime，可能有一点延后，但因为 AP 查询对延迟不敏感，让查询多等一会就可以了。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>看这种工业 DB 的论文就是大而全的感觉，细节讲的不深，实际上论文里一句资源隔离做起来就是天大的工作量，有些看的时候的疑问，说不定实践里都有解决。另外阿里云原生就是比云原生要好用，词条长就是厉害啊。</p><p>DN 层有完备的执行引擎，这点是很方便的，可以轻松的拆分计划下发。原本 PolarDB 一写多读的架构在通过将 coordinator 移到 CN 层知乎，去除 write 单点的问题，RO 节点变成扩展读能力的工具，可谓是变废为宝。</p><p>将近看完的时候才想起来 PolarDB-X 是有开源的，大家也可以多多关注开源动态：</p><ul><li><a href="https://github.com/polardb/polardbx-sql">https://github.com/polardb/polardbx-sql</a></li><li><a href="https://github.com/polardb/polardbx-engine">https://github.com/polardb/polardbx-engine</a></li></ul>]]></content:encoded>
      
      
      
      
      <comments>https://blog.tongmu.me/2023/06/18/PolarDB-X-notes/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Google Mesa 笔记</title>
      <link>https://blog.tongmu.me/2023/06/06/google-mesa-notes/</link>
      <guid>https://blog.tongmu.me/2023/06/06/google-mesa-notes/</guid>
      <pubDate>Tue, 06 Jun 2023 17:51:50 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Papar: <a href="https://research.google/pubs/pub42851/">https://research.google/pubs/pub42851/</a></p><p>Mesa 是 Google 用于分析广告数据的 AP 数据库，既然是最重要的业务，当然有最高的要求：</p><ul><li>能够存储 PB 级别的数据</li><li>极高的写入吞吐，百万级别</li><li>分钟级的可见</li><li>事务原子性</li><li>跨地域部署和容灾</li><li>分区一致性</li><li>可用性</li><li>百毫秒级别的查询延迟</li><li>在线 schema 变更</li><li>滚动升级</li></ul><p>以上这些问题，没有一个现有的 data warehouse 系统能够全部解决，所以需要 Mesa。</p><p>为了支持可重复读，Mesa 的数据是多版本的，同时为了保证一致性，Mesa 建立在 Paxos 之上（看人家 Google 就不整多写多读的活）。</p><p>我们先来批判一下某些现有的 AP 系统：</p><ul><li>非实时，一般在使用这种系统时，用户会选择几分钟导入一次增量数据，这能够满足一些非实时的需求，有的企业喜欢每天跑批的，用用这种系统就差不多得了。</li><li>吐槽了一些一些论文工作的不足，有的没有考虑到超大数据，有的只考虑了 in-mem 的 AP 问题处理。</li></ul><p>这篇论文的工作：</p><ul><li>提供了事务 ACID，Google 真的很在意这一点…</li><li>整了个新的 Version Control 系统，能够用 batch update 来提高吞吐（牺牲一点延迟）</li><li>Data 异步复制，meta 同步复制，异步复制能够让吞吐更高</li><li>大量的 schema change 不影响性能，估计支持并发</li><li>能够应对数据损坏</li></ul><h2 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a>Storage</h2><p>Mesa 在定义 table 的同时要求定义一个 aggregation function $F: V \times V \to V$来做数据聚合。这个 function 要满足结合律（方便做 batch 优化），最好满足交换律，这样子我们可以以一种更随意的方式来定序。简单的例子是 SUM 满足交换律，但是一个 register 模型不满足，他们的优化手段自然会有所不同（SUM 的性能会更好）。</p><p>当然实际上的 V 会是一个 tuple，所以需要为 tuple 的每一个 element 分别定义 aggregration function。</p><p>做 batch 时存在一个 trade-off，batch 越小，latency 越低，消耗资源越频繁，占用空间越大；反之 batch 越大，latency 越高，整体的吞吐就越高，占用空间也越小。在我们定义了 aggregation function，如何做 batch 在理论上就变得很简单了。</p><p>查询时会使用一个 version number n 来进行，为了保证可重复读，需要确保 version &lt; n 的 update 全部已经写入并且可读。</p><p>为了保证 monotonic，Mesa 需要按照 version 的顺序 apply update，这样使得 Mesa 能够处理先加后减的 case。</p><p>Mesa 认为以行为单位存储多版本会有问题，体现在三个方面：</p><ol><li>消耗的空间太大</li><li>查询的时候遍历所有太慢</li><li>在查询时将它们聚合起来也很慢</li></ol><p>所以 Mesa 的多版本实际是存的 delta 数据，因为它至少满足结合律，只要按顺序聚合运算 delta，最后就能够得到正确的结果。但是他们认为 delta 数据会比整个 V 小得多？</p><p>显而易见的，当 delta 太多时，也会带来很大的空间消耗和查询计算开销，Mesa 通过 compaction 在降低 delta 精度的同时压缩大小和查询时计算的 delta 数量。简单的，将 10 条 delta 压缩成一条后，我们就无法在这个 delta 的时间区间中做更细致的查询了。但是对于时序数据而言，稍微旧一些的数据往往不需要太高的精度。这种 compaction 策略是可以配置的。看到这里感觉所谓的时序数据库已经被干裂了。</p><p>Mesa 在存储数据时，会把数据转化为列存格式，这样在某些查询中就只需要读取部分列而非整行，减少了数据的读取量，并且尽可能用连续数据来满足查询的需求。</p><p>每个 data file 都有一个对应的 index file，index file 存了每个 key 的 offset，定位到这个 offset 之后，就可以读到 base data 并且进行 delta 的累加，因为 index file 里的 key 长度是固定的，所以它可以对给定的 key 进行二分检索，速度会很快。</p><h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>前面基本把理论都讲的差不多了，然而实现往往比理论困难得多，Mesa 将无状态的服务拆分成 update/maintenance 和 querying 两部分，看名字就知道前者是写入路径，后者是读取路径。Mesa 将状态存储在 BigTable 和 Colossus 上，前者存 meta，后者存 data，不愧是 Google，分布式 KV 和文件系统都是开箱即用的状态。</p><p>update/maintenance server 能够扩展的关键在于，controller 能够按照 table 维度进行拆分，防止了全局的单点。而一个 controller 的能力基本上足够控制一个表上的 update 操作。</p><p>在 querying server 的实现上，Mesa 考虑了需要低延迟的小查询与超大查询共存的问题，怎么调度就没有展开说。另外 querying server 是对等的，但是 Mesa 会考虑数据亲和性，将对相同数据的查询放到同一个 querying server 上面去执行，这样可以有尽可能多的 in-mem 查询（而不需要从 Colossus 上读文件），具体做法就是秘密了。</p><p>前面我们还提了跨地域部署的需求，为了做到这点，Mesa 把上面讲的 update/maintenance 和 querying 统称为一个 instance。一个 instance 是在一个 data center 里的服务合集，存了一份完整的数据，所以在 instance 内部，处理查询是简单的，读本地文件就行了。为了管理这些 instance 的写入，Mesa 又引入了一个叫 committer 的东西，这个东西本身也是无状态的，每个 instance 都会带一个，但是它会用一个叫 versions database 的东西来管理 update batch 的 version number 分配和 version 对应 batch 的状态。这有点像 etcd 做的事，如果我们要把所有的状态都用一个 paxos state machine 管理起来，那肯定会遇到吞吐的问题，但是我们只让这个 state machine 管理 meta 信息，就能把整体的吞吐放大到一个很客观的数值。</p><h2 id="Enhancement"><a href="#Enhancement" class="headerlink" title="Enhancement"></a>Enhancement</h2><p>Mesa 简单说了说他们的优化，但我感觉这只是他们觉得比较有代表性的：</p><ul><li>delta prune，如果 delta 设计的时间完全没有落在查询区间内，可以跳过这个 delta</li><li>scan-to-seek，在 scan 的过程中利用 seek 跳过不可能的 row 来加速查询</li><li>resume key，如果一个 querying server 挂了，Mesa 可以用 resume key 在另一个 querying server 上继续未结束的查询，大概是经历过跑超大查询被中断的痛吧</li></ul><p>如果一个 key 上的版本（delta）很多，即使有上面所说的 compaction，累加计算这些 delta 还是会很慢，这里 Mesa 用 MapReduce 来做并行，再连续的 delta 记录中用 sample key 的概念来做拆分，个人感觉这里不是什么难做的点，因为它的 row 是满足结合律的，嗯加并发最后按顺序加起来就行了（如果还满足交换律的话都不用考虑顺序）。</p><p>Schema Change 是一个绕不开的问题，Mesa 要求 online schema change，但是根据使用场景不同分了两种方法：昂贵的万金油 A，便宜但是能满足大部分场景的 B。</p><p>A 的方法是复制整表，然后把 update 同时写入旧表和新表，当两张表的进度一样并且 query 完全切换到新表之后，对应的 table name 将指向新表。</p><p>相比之下，B 就不需要复制整表，切换过程大概做了两件事：1. 使用新的 schema，2. 写下包含所有 schema 变化的 delta 记录。这种感觉就适用于 add column 这种简单的事情。</p><p>Mesa 觉得文件级别的 checksum 不够用（如果有多处错误，checksum 可能阴差阳错的相同），为了防止这种阴差阳错的情况，Mesa 在每次 query 和 udpate 时都会校验一些基本约束，比如 key 的顺序性。Mesa 还在 instance 之间进行多种 checksum 的检验。当发生 data corruption 的时候，Mesa 可以从其他 instance 直接复制 table，如果要复制的数据太多，还可以从备份恢复到旧版本后回放最近的 update。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>如果一个在 2014 年之后出生的流数据库不参考 Mesa 的工作是不行的，但是 Mesa 也多次提到了这是 Google 的需求，不一定适合所有人，有这么多数据的公司不多了。</p>]]></content:encoded>
      
      
      
      
      <comments>https://blog.tongmu.me/2023/06/06/google-mesa-notes/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>风景摄影-2023-04</title>
      <link>https://blog.tongmu.me/2023/04/16/photography-2023-04-1/</link>
      <guid>https://blog.tongmu.me/2023/04/16/photography-2023-04-1/</guid>
      <pubDate>Sun, 16 Apr 2023 22:50:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>月初请假出去自驾了一下 G214 和 G318，G214 从香格里拉出发，到芒康汇入 G318，最后抵达拉萨。</p><p>G214 上车很少，路况也很好，路过飞来寺但是赶时间没有去参观，当天抵达芒康的时候已经将近十点。第二天六点多出发赶去排队怒江大桥的交通管制，本篇主要是这部分旅途中的照片。</p><pre><code>特别感谢我的小朋友在修图上给的鞭策和指导。</code></pre><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2023-04/DSC05132.50.jpg"></p><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2023-04/DSC05496.jpg"></p><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2023-04/DSC05527.jpg"></p><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2023-04/DSC05679.jpg"></p><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2023-04/DSC05715.50.jpg"></p><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2023-04/DSC06230.jpg"></p><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2023-04/DSC05741.50.jpg"></p><p>G318 很美也很成熟，值得走一次，但我也只推荐走一次。</p><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2023-04/DSC05711.50.jpg"></p>]]></content:encoded>
      
      
      
      
      <comments>https://blog.tongmu.me/2023/04/16/photography-2023-04-1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>CRDB Global Database</title>
      <link>https://blog.tongmu.me/2022/07/31/crdb-global-database/</link>
      <guid>https://blog.tongmu.me/2022/07/31/crdb-global-database/</guid>
      <pubDate>Sun, 31 Jul 2022 18:08:34 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>CRDB 在 SIGMOD 2022 上发表了一篇关于他们如何做 multi-region DB 的论文「Enabling the Next Generation of Multi-Region Applications with CockroachDB」，为这个题目交上了一份相对完整的答案。</p><p>Multi-Region 的需求来源于高可用和政策要求（例如 GDPR）。为此，CRDB 引入了一些基础概念：</p><ul><li>Region，地理上的区域<ul><li>Zone，Region 下面的可用区</li></ul></li><li>Table locality，是否为本地表，本地表指主要的访问都来自于一个 region 内</li><li>Survivability goal，保持服务可用的情况下能够容忍的错误（zone failure or region failure）</li></ul><p>这些概念都能够用 SQL 进行表达，并且能够与 DDL 语句无缝结合。同时 CRDB 也有针对不同条件的优化，例如本地表的全局唯一性检测不需要访问远程节点。</p><p>这篇文章主要做的工作是：</p><ul><li>通过将上述三个概念结合到 SQL 中，极大简化 multi-region 的配置</li><li>优化器支持 geo-partition</li><li>只读事务的 serializability</li><li>单 key 事务的 strict serializability</li></ul><h2 id="抽象与-SQL"><a href="#抽象与-SQL" class="headerlink" title="抽象与 SQL"></a>抽象与 SQL</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cockroach start \</span><br><span class="line">--locality=region=us-east-1,zone=us-east-1b <span class="comment"># ...</span></span><br></pre></td></tr></table></figure><p>CRDB 在命令行之中指定 region 和 zone，最后整个集群的 region/zone 是所有 node region/zone 的总和，可以通过 <code>SHOW REGIONS</code> 查看。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE movr <span class="keyword">PRIMARY</span> REGION &quot;us-east1&quot; REGIONS &quot;us-west1&quot;, &quot;europe-west1&quot;;</span><br><span class="line"><span class="keyword">ALTER</span> DATABASE movr <span class="keyword">ADD</span> REGION &quot;australia-southeast1&quot;;</span><br><span class="line"><span class="keyword">ALTER</span> DATABASE movr <span class="keyword">DROP</span> REGION &quot;us-west1&quot;;</span><br></pre></td></tr></table></figure><p>CRDB 通过 SQL 执行 database 所属的 region</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> DATABASE movr SURVIVE REGION FAILURE;</span><br><span class="line"><span class="keyword">ALTER</span> DATABASE movr SURVIVE ZONE FAILURE;</span><br></pre></td></tr></table></figure><p>通过指定可用性的目标，CRDB 能够更加灵活的调度副本，在可用性目标的容忍范围内，当遇到 region/zone failure 时候，写入请求最多增加一个离最近 region 的 RTT，读请求则不受影响。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> west_coast_users ( ... ) LOCALITY REGIONAL <span class="keyword">BY</span> <span class="keyword">TABLE</span></span><br><span class="line"><span class="keyword">IN</span> &quot;us-west1&quot;;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> users ( ... ) LOCALITY REGIONAL <span class="keyword">BY</span> <span class="type">ROW</span>;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> promo_codes <span class="keyword">SET</span> LOCALITY <span class="keyword">GLOBAL</span>;</span><br></pre></td></tr></table></figure><p>建表语句能够指定表的 locality，<code>BY TABLE/ROW</code> 的表会优化那一张表/行在指定 region 下的读写性能，<code>GLOBAL</code> 则会优化全局的读性能，牺牲写性能。</p><p><strong>自动分区</strong>会 row 放在它被 insert 的分区中，<strong>自动迁移（<code>ON UPDATE rehome_row()</code>）</strong>会将 row 放到它最近被 update 的分区中，为了防止抖动，默认不打开自动分区。</p><p>对于那些已经支持分区的应用，他们或许不愿意在 insert 语句中额外指定分区，此时可以使用 <code>REGIONAL BY ROW</code> DDL 语句。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">crdb_region crdb_internal_region <span class="keyword">AS</span> (<span class="keyword">CASE</span> <span class="keyword">WHEN</span> state <span class="operator">=</span> <span class="string">&#x27;CA&#x27;</span></span><br><span class="line"><span class="keyword">THEN</span> <span class="string">&#x27;us-west1&#x27;</span> <span class="keyword">ELSE</span> <span class="string">&#x27;us-east1&#x27;</span> <span class="keyword">END</span>) STORED</span><br></pre></td></tr></table></figure><p>对于 <code>REGIONAL BY ROW</code> 的表，可以将 <code>crdb_region</code> 定义为一个计算列，当条件中有 <code>state</code> 时，就会按照这个规则去做 local 查询。</p><h2 id="Placement"><a href="#Placement" class="headerlink" title="Placement"></a>Placement</h2><p>CRDB 使用 <a href="https://www.notion.so/Enabling-the-Next-Generation-of-Multi-Region-Applications-with-CockroachDB-990d2a5971b1480ab89b0715d2bf4326">zone configurations</a> 来配置 placement，CRDB 在 v21.1 支持了 non-voting replicas，也叫 read-only replicas，因此就有了这么一堆看起来很繁琐的配置。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">// The difference between num_replicas and num_voters</span><br><span class="line">// determines the number of non-voting replicas.</span><br><span class="line">num_voters = &lt;int&gt;</span><br><span class="line">num_replicas = &lt;int&gt;</span><br><span class="line"></span><br><span class="line">// constraints applies to both voting and non-voting</span><br><span class="line">// replicas. It fixes a replica count per-region,</span><br><span class="line">// allowing the remainder to be placed freely.</span><br><span class="line">// voter_constraints is similar but for voters only.</span><br><span class="line">constraints = &#123;</span><br><span class="line">+region=&lt;string&gt;: &lt;int&gt;,</span><br><span class="line">+region=&lt;string&gt;: &lt;int&gt;,</span><br><span class="line">+region=&lt;string&gt;: &lt;int&gt;,</span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line">voter_constraints = &#123;+region=&lt;string&gt;: &lt;int&gt;, ... &#125;</span><br><span class="line"></span><br><span class="line">// lease_preferences pins the leaseholder to a specific</span><br><span class="line">// region, allowing for consistent reads from within.</span><br><span class="line">lease_preferences = [[+region=&lt;string&gt;]]</span><br></pre></td></tr></table></figure><p>但是这些繁琐的配置相比于如 “我要求 region failure 时服务不中断” 的口头语还是来的更好用。上一节所说的 locality 配置（<code>REGION BY TABLE/ROW</code> ）就是通过 zone configurations 来实现的。</p><ul><li>Home region，主要发生读写的 region</li><li>Zone survivability，在 zone failure 的 survivability 要求下，3 个 voting replicas 都会被分配在 home region 中（不同的 zone 里），non-home region 里会有 non-voting replicas 来加速读</li><li>Region survivability，region survivability 需要容忍 region failure，因此要求至少有 3 个可用 region，在 home region 中有 2 个副本能够成为 candidates，因此 N region 的集群中会有 $𝑚𝑎𝑥 (2 + (𝑁 − 1), 𝑛𝑢𝑚_𝑣𝑜𝑡𝑒𝑟𝑠)$ 个副本</li><li>Placement Restricted，最后，因为一些合规的要求（如 GDPR），有些数据不能够出 region，因此 zone survivability 的数据库能够加上 placement restricted 约束，这样所有的 replica 都会确保在 home reigon 内（但是和原本的 zone survivability 有何区别？）。Placement restricted 对 global table 没有效果，并且不能和 region survivability 同时配置</li></ul><h2 id="考虑-locality-的优化器"><a href="#考虑-locality-的优化器" class="headerlink" title="考虑 locality 的优化器"></a>考虑 locality 的优化器</h2><h3 id="Unique-Constraint"><a href="#Unique-Constraint" class="headerlink" title="Unique Constraint"></a>Unique Constraint</h3><p>CRDB 的 <code>REGIONAL BY ROW</code> 表能够不使用显示的分区 column（也没有用隐藏列），为了保证全局的唯一性，CRDB 为每个 insert/update 语句并行的在每个分区做唯一性检测，这里有 corss-region latency，而为了尽可能降低这种请求带来的延迟，CRDB 在某些情况下会跳过唯一性检测（默认新数据也是唯一的）：</p><ul><li>UUID 列，因为碰撞率非常低，默认不检查</li><li>索引定义上有 <code>crdb_region</code> 标记，如 <code>UNIQUE (crdb_region, col)</code></li><li>将 crdb_region 定义为一个 unique column 的生成列，此时 partition 的唯一性能够推断 global 的唯一性</li></ul><h3 id="Locality-Optimized-Search-LOS"><a href="#Locality-Optimized-Search-LOS" class="headerlink" title="Locality Optimized Search (LOS)"></a>Locality Optimized Search (LOS)</h3><p>当使用一个唯一索引作为查询条件时，至多能找到一条数据，CRDB 会先在本地查询数据是否存在，只有当本地不存在时，才去其他 partition 查找。将这个思路扩展，任何返回有限行的查询（例如 limit 和 where in）都能够优先做本地查找，再做远程查找。同理，在 join 中，根据左表查询右表的值时，也能够使用 LOS 优化。（个人意见，LOS 是一种乐观策略，应该在某些情况下有回退）</p><h2 id="Stale-Read"><a href="#Stale-Read" class="headerlink" title="Stale Read"></a>Stale Read</h2><p>为了加速查询，CRDB 对读取时所使用的副本做了三个优化：</p><ul><li>Follower Read</li><li>Non-voting replicas Read</li><li>Stale Read</li></ul><p>这些都是一些比较常见的优化，主要工作是确认 Raft log 的 committed index 是否复合读的要求，说起来比较复杂，这里不展开说了（懒）</p><h2 id="Global-Transaction"><a href="#Global-Transaction" class="headerlink" title="Global Transaction"></a>Global Transaction</h2><p>这篇论文中说它提出了 a novel global transaction protocol，指的就是这个 global transaction，所以重点来讲讲这部分。这个 global transaction protocol 是为上面提到的 global table 准备的，回顾一下 global table 的要求：</p><ul><li>所有 region 都能够 local read</li><li>写入性能会受到影响</li></ul><p>CRDB 采用的方案叫 “write into the future”，写入一条未来 timestamp 的数据，并且 commit 线程要等待<strong>本地的</strong> HLC 时钟超过这个 future timestamp 才返回成功，在次之前都是 uncertainty window，但它只延迟返回事务成功，2PC 的 lock 会在第一时间被清理不会被推迟。</p><p>我们知道在使用 HLC 时，当读事务遇到 uncertainty window 时，需要重启事务用更新的 timestamp 来消除 uncertainty window 带来的破坏 linearizability 的风险（uncertainty refresh），图 step3 就需要做 uncertainty refresh。上面提到了，future write 返回成功的条件是 <code>local HLC &gt; future timestamp</code>，所以可能存在有的节点的 HLC 仍然小于 future timestamp 的情况，那么仅仅靠 uncertainty refresh 机制，就可能产生“提前读到”的问题。假如 w 是一个 future write 事务，r 读到了 w 的写入，随后的 r’ 没有读到 w 的写入。在真实时间上，发生的顺序是 r → r’，但是从读取的结果来看则是 r’ → w → r，这就违背了 linearizability。这里会让人困惑，都有 uncertainty refresh 机制的保证了，为什么还会提前读到呢？因为 uncertain window 是 HLC 的物理时间偏差的上限，但是 future timestamp 并不是取自 HLC 时间的，假设下面这种情况（uncertain window 取 250ms）：</p><ul><li>HLC(w) = 1000ms</li><li>HLC(r) = 1100ms</li><li>HLIC(r’) = 900ms</li><li>future timestamp = 1200ms</li></ul><p>当 HLC(r) 进行读取时，它的 uncertain window 是 <code>[1100ms, 1350ms]</code>，当遇到 future timestamp 时，它会重启并且将 uncertain window 更新为 <code>[1201ms, 1350ms]</code>，再次读取时即可读到这条 future write。但是，future timestamp 落在了 HLC(r’) 的 uncertain window 之外，因此 r’ 没有机会发现在自己的uncertainty window 里有一条数据，也没有机会做 uncertainty refresh。这里的关键点在于根据 future timestamp 来推 ts 是不安全的。</p><p><img src="global-txn-wait.png" alt="global-txn-wait"></p><p>解决这个问题也很简单，当读事务发现在自身 uncertain window 之外的 future timestamp 时（图中 step3，如上述 r’），可以忽略这条 future write；但是当读事务发现在自身的 uncertain window 之内的 future timestamp 时（图中 step4，如上述 r），则需要等待本地的 HLC 超过 future timestmap 时在进行读取，此时即可保证 r’ 的 HLC 的 uncertain window 至少能够发现这条 future write，防止 linearizability 被破坏。</p><h3 id="Local-Read"><a href="#Local-Read" class="headerlink" title="Local Read"></a>Local Read</h3><p>Global transaction 的一个要求是所有的 region 都能够进行 local read，那么这里就需要考虑副本读的兼容性，由于 Raft 的顺序性约束，副本读只需要保证 closed timestamp 被正常推进，就能够不漏读。因此关键点不在于给 future write 设置多长的 commit wait（当出现系统抖动时，wait 总有低于网络延迟的时候），而在于副本读需要从 write quorum 处获取到最新的 closed timestamp。</p><h2 id="个人评价"><a href="#个人评价" class="headerlink" title="个人评价"></a>个人评价</h2><p>这篇论文从工程学术两方面手把手的教人做 global database，看完之后感叹他们的格局真是大啊。俗话说“一流企业做标准”，如果盯着 MySQL 源码去魔改，大概这辈子也走不到这一步吧。</p>]]></content:encoded>
      
      
      
      
      <comments>https://blog.tongmu.me/2022/07/31/crdb-global-database/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Epyc 服务器之坑</title>
      <link>https://blog.tongmu.me/2022/07/03/build-a-epyc-server/</link>
      <guid>https://blog.tongmu.me/2022/07/03/build-a-epyc-server/</guid>
      <pubDate>Sun, 03 Jul 2022 11:39:21 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>近期组了一台双路 Epyc 的服务器，这篇博客记录组机器时候的一些坑点，供朋友们参考。</p><p><img src="cpus.png" alt="CPUs"></p><p>Epyc 是 AMD 为服务器设计的 CPU，大概长这样。</p><p><img src="epyc-socket.jpg" alt="Epyc Socket"></p><h2 id="单路-多路"><a href="#单路-多路" class="headerlink" title="单路 - 多路"></a>单路 - 多路</h2><p>仔细观察上图的 CPU 型号为 <strong>7302P</strong>，同时 AMD 还有一款 CPU 型号为 <strong>7302</strong>，带 P 后缀的说明这个 CPU 只支持单插槽的，如果想组双路的话就要避开这类型号。除此之外这 <strong>XXXX</strong> 与 <strong>XXXXP</strong> 的性能几乎相同。</p><p><img src="7302-7302p.png" alt="7302-7302P"></p><h2 id="CPU-代号"><a href="#CPU-代号" class="headerlink" title="CPU 代号"></a>CPU 代号</h2><p>首先看 Epyc 的代号名称。</p><table><thead><tr><th>代数</th><th>代号</th><th>发布年份</th></tr></thead><tbody><tr><td>1</td><td>Naple</td><td>2017</td></tr><tr><td>2</td><td>Rome</td><td>2019</td></tr><tr><td>3</td><td>Milan(-X)</td><td>2021</td></tr><tr><td>4</td><td>…</td><td>2022</td></tr></tbody></table><p>四代代号比较多这里不写了，目前 3/4 代大船没靠岸大多也买不起。而一代和二代之间则优先推荐二代（一代是 14nm，二代是台积电 7nm）。在 CPU 的代号中，代数体现在最后一个数字上，上面提到的 <strong>7302</strong> 就是二代 CPU。中间两位数字简单地说就是越大越好，感兴趣的朋友可以去 <a href="https://en.wikipedia.org/wiki/Epyc#Second_generation_Epyc_(Rome)">wiki</a> 看看售价和参数。</p><h2 id="主板"><a href="#主板" class="headerlink" title="主板"></a>主板</h2><p>我选择的是超微 H11DSi，海鲜市场 1250 买的，这里说一下几种型号的差别。</p><ul><li><a href="https://www.supermicro.com/ja/products/motherboard/H11SSL-i">H11SSL-i</a> / <a href="https://www.supermicro.com/ja/products/motherboard/h11ssl-c">H11SSL-C</a> / <a href="https://www.supermicro.com/ja/products/motherboard/h11ssl-nc">H11SSL-NC</a></li><li><a href="https://www.supermicro.com/en/products/motherboard/H11DSi">H11DSi</a></li><li><a href="https://www.supermicro.com/ja/products/motherboard/h11dsi-nt">H11DSi-NT</a></li></ul><p>H11SSL 系列只支持一个 CPU，如果上面选择了 <strong>XXXXP</strong> 的话可以考虑，这三款具体的区别我没有研究过。</p><p>H11DSi 的两款都支持双路，NT 版支持两个 NVMe 接口，如果像我一样选择 H11DSi 的话后续就只能上 PCI-e 的 SSD 了。</p><h2 id="风扇"><a href="#风扇" class="headerlink" title="风扇"></a>风扇</h2><p>组机器之前我十分害怕服务器暴力扇的噪音，多次在某宝浏览猫扇，然后卖主板的商家推荐我上拆机风扇，用了之后感觉很好，这里安利一下，原因有几点。</p><ul><li>几乎没有声音，甚至不如空调声音响</li><li>肯定能装上去</li><li>风道方向正常</li></ul><p>组完之后几乎没有风扇声，即使在跑 cinebench multicore 的时候，也能在听不到风扇声的情况下把温度压在 60 度之内，另一个原因是我的 CPU TDP 不高，没超频的情况下产生的热量还是比较少的。</p><p>服务器主板上的散热器是特制的，有严格的安装步骤和螺丝孔位，如果选择家用散热器，可能会遇到装不上去的情况。</p><p>风道方向比较抽象，我画了张图来说明：</p><p><img src="cpu-fan.png" alt="CPU fan"></p><p>图中 1 是家用 CPU 风扇的安装方法，而 2 是服务器 CPU 风扇的安装方法，区别是风扇被安装在 CPU 的窄边（主板就是这么设计的）。如果我们按照家用风扇的装法强行安装到服务器 CPU 上，风道就会变成 3 这个样子，往上吹了，当然也有可能根本装不上（摊手。</p><h2 id="机箱"><a href="#机箱" class="headerlink" title="机箱"></a>机箱</h2><p>主板的选择会对机箱尺寸提出要求，我选择的 H11DSi 是 E-ATX 尺寸的，买的时候千万看好别拿到手发现塞不进去了。</p><h2 id="显示"><a href="#显示" class="headerlink" title="显示"></a>显示</h2><p>H11DSi 主板上有集成显卡，但是只支持 VGA 接口，不建议买 HDMI 的亮机卡（反正我买了点不亮），最好直接用 VGA 接口的显示器（可能比亮机卡更便宜）。</p><h2 id="完"><a href="#完" class="headerlink" title="完"></a>完</h2><p>就写到这里，后续有想到的坑点再补充。</p>]]></content:encoded>
      
      
      
      
      <comments>https://blog.tongmu.me/2022/07/03/build-a-epyc-server/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>「天聲」 - 个人翻译</title>
      <link>https://blog.tongmu.me/2022/06/19/ten-no-koe/</link>
      <guid>https://blog.tongmu.me/2022/06/19/ten-no-koe/</guid>
      <pubDate>Sun, 19 Jun 2022 20:56:35 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><pre><code>本文为「天聲」的个人翻译，不提供原文与音乐下载，大家多多支持正版。</code></pre><p>传送门：<a href="https://icddecadence.com/3rdalbum/">https://icddecadence.com/3rdalbum/</a></p><hr><center style='font-family: Georgia, "游明朝", "Yu Mincho", "游明朝体", YuMincho, "ヒラギノ明朝 Pro", "Hiragino Mincho ProN", "MS P明朝", "MS PMincho", HGS明朝E, "MS Mincho", serif;'>痛苦随着声音响彻云霄。<br><br>向你传达。<br>天之声。<br><br>初生的生命是爱的赞歌<br>沉重的悲伤与绝望，沉思死亡是为了寻找生的希望<br>正如痛苦不会终结，不必沉溺于悲伤<br>如斩断永劫的螺旋般，奏响天之声（てんせい）―――。<br><br>君如我歌，消散不留回声<br><br>沉入黑暗时也会高举手臂寻求光明吧<br><br>蒙受水刑的原罪却能够获得拥抱，即使知道处决祭坛的痛苦，也想去往那个地方<br><br>忧虑爱情，饱食哀愁，歌颂天之声（てんのこえ）―――。<br><br>扼杀痛苦，鲜血淋漓<br>拧断翅膀，脚步不停，直至地平线的尽头<br><br>如斩断永劫的螺旋般，奏响天之声（てんせい）<br><br>即使在苦难之中，眼前被黑暗所覆盖<br>也不会放过一丝光线，直到生命的尽头―――。<br><br>遇见光明，唱响歌声―――。<br><br>扼杀痛苦，鲜血淋漓<br>拧断翅膀，脚步不停，踏向地平线的尽头<br><br>如斩断永劫的螺旋般<br>万众瞩目之下<br>燃尽干枯的泪水<br>奏响天之声（てんせい）<br><br>斩断永劫的螺旋<br><br>呜呼，天之声（てんのこえ）啊―――。</center>]]></content:encoded>
      
      
      
      
      <comments>https://blog.tongmu.me/2022/06/19/ten-no-koe/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Tales of the Tail</title>
      <link>https://blog.tongmu.me/2022/05/22/Tales-of-the-tail/</link>
      <guid>https://blog.tongmu.me/2022/05/22/Tales-of-the-tail/</guid>
      <pubDate>Sun, 22 May 2022 15:51:09 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><ul><li><a href="https://drkp.net/papers/latency-socc14.pdf">https://drkp.net/papers/latency-socc14.pdf</a></li></ul><p>朴实的讲述优化尾延迟的方法以及其效果的工作，目的是为了寻找一个理想的、可达到的延迟分布目标。</p><h2 id="延迟的来源"><a href="#延迟的来源" class="headerlink" title="延迟的来源"></a>延迟的来源</h2><ul><li>操作系统上其他线程的影响</li><li>请求发送过程中的重排序（发出的顺序与收到的顺序不同）</li><li>应用的设计，如处理网络传输线程的调度</li><li>多核处理器中的问题，例如网卡中断，服务进程如何使用 CPU 核</li><li>CPU 的节能策略（狗头）</li></ul><p>优化延迟的策略都是民间流传已久的，这篇文章的贡献主要在于衡量这些策略的效果，以及为优化尾延迟制定一个理想的模型，理论上可达到，符合现实中的规律。在大量的实验之后，得出一个结论是吞吐和尾延迟之间存在 tradeoff，两者不可兼得。</p><h1 id="估算延迟"><a href="#估算延迟" class="headerlink" title="估算延迟"></a>估算延迟</h1><p>理想的延迟分布可不可能是均匀的呢？所有请求的延迟都一样，这样就不需要讨论尾延迟的问题了！但并不能，一个极端的例子，遇到请求量激增超过服务处理能力的情况，尾延迟一定会升高。通过实验，能够观测到延迟有如下的特点：</p><ul><li>即使有一个能够在确定时间里处理任何请求的服务器，延迟仍然会因为网络传输的时间而不一</li><li>延迟分布与服务器负载情况有关，服务器的负载越高，尾延迟也会更高</li><li>在服务器的整体负载保持不变的情况下，更多的处理器能降低尾延迟</li><li>服务器上 queue 的策略也会影响尾延迟，FIFO 策略是尾延迟最低的，但其他策略可以做到更低的平均延迟，tradeoff</li></ul><p>首先对请求的到达顺序建模，请求的到达顺序并不严格等于发出顺序，服务端用一个策略处理收到的请求，比如 FIFO，此时可以将这个处理任务的队列表示为 A/S/c，A 表示请求到达的延迟分布，S 表示服务端处理请求的时间分布，c 表示服务端的 worker 数量。</p><p>Figure 1 是单核 70% 负载，请求处理时间为 50μs 时的尾延迟分布，纵轴的 <a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function#Complementary_cumulative_distribution_function_(tail_distribution)">CCDF</a> 则是尾延迟的数学表示。纵轴 y 对应到横轴的值 x 即为 (1-y) 的分位线。</p><p><img src="figure-1.png" alt="figure-1"></p><p>Figure 2 是使用 <a href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson 分布</a>对单核增加负载时的尾延迟变化，单核负载增加意味着突然的请求量增加更容易出现请求堆积。负载从 50% 增加到 95%，.99 分位线增加了 10 倍。所以一个降低尾延迟的方法是：降低服务器负载。</p><p><img src="figure-2.png" alt="figure-2"></p><p>Figure 3 是使用 Poisson 分布对不同核数的测试，保持每个 CPU 平均收到的请求数量相同，8c 的延迟是 1c 的 1/4。这个优化在所有线程都从一个共享的 queue 获取请求的前提下才生效，如果每个线程只 poll 自己的 queue，那么延迟不会降低，这里有 work stealing 的感觉。这个规律是重要的，<strong>我们容易理想的以为对于一个理想的应用，将一个服务从 8c 降低到 4c，所能提供的服务能力（吞吐）会减半，同时尾延迟应当保持不变，但是这个实验表明如果想让尾延迟不变，那么 4c 所能提供的吞吐不如 8c 的一半。</strong></p><p><img src="figure-3.png" alt="figure-3"></p><p>Figure 4 是使用了不同的 queue 策略的测试，50μs 的处理延迟，4 个 worker 以及 80% 的负载，可以看出来策略不同也会产生不同的延迟分布。</p><ul><li>FIFO，全局共享的 FIFO queue</li><li>LIFO，全局共享的 LIFO queue</li><li>Random Worker，将 request 随机分配给 worker，每个 worker 维护自己的 FIFO queue</li><li>Random Request，每个 worker 从全局共享的的 queue 中随机挑选下一个处理的请求，queue 的请求被选中的概率相等（与到达时间无关）</li></ul><p>实验说明 LIFO 虽然尾延迟比 FIFO 更高，但是平均延迟更低，论文中的数据为 50μs vs 64μs（不明白 50μs 是怎么算出来的，最低延迟就是 50μs，加上更高延迟的一起算，怎么都会大于 50μs 才对）</p><p><img src="figure-4.png" alt="figure-4"></p><h1 id="延迟测量方法"><a href="#延迟测量方法" class="headerlink" title="延迟测量方法"></a>延迟测量方法</h1><p>上一节描述了一个理想系统的延迟分布，本节将要对真实系统进行测量，找出它与理想系统的差距与原因，最后通过优化这些因素让他尽可能的接近理想系统。这篇文章中有三个被测对象：</p><ul><li>自己编写的非 RPC 程序，通过 TCP 协议读取 128 byte，然后写回 128 byte。</li><li>Memcached，内存 KV 存储，有 TCP 和 UDP 模式，CPU 密集型</li><li>Nginx，静态服务器，使用事件驱动的异步设计，IO 密集型</li></ul><p>为了测量 server 之外的延迟（OS，应用），测试时在从网卡收到请求后以及在将返回写入网卡之前打了两个点。</p><h1 id="延迟的根源"><a href="#延迟的根源" class="headerlink" title="延迟的根源"></a>延迟的根源</h1><p>Figure 5 是使用单核单 worker 测试的结果，图中 standard linux 与 ideal server 的尾延迟差距巨大，而调整 linux 进程的 nice 值到 -20 之后，尾延迟稍有缓解。使用 realtime scheduler 能让 server 应用的优先级严格高于其他进程，这个调度策略对尾延迟有显著的改善。对比 dedicated core 的结果，realtime scheduler 的调度方式已经非常理想了。Realtime scheduler 会使用 FIFO 方法来调度同一优先级的进程，这对尾延迟也有好处（记得前面说 FIFO 是尾延迟最低的）。</p><p><img src="figure-5.png" alt="figure-5"></p><p>操作系统对线程的调度方式也会对尾延迟产生影响，Figure 6 是对比修改后的 CFS（为 worker 进程添加了高优先级）和 realtime scheduler 尾延迟的结果，结果和 Figure 4 相似，通过实验证明了 FIFO 是能够降低尾延迟的调度策略（在进程调度层面）。</p><p><img src="figure-6.png" alt="figure-6"></p><p>Figure 7 通过增加处理线程数来降低尾延迟，其降低的幅度和 ideal server 相当，但是 Memcached TCP 与 Nginx long TCP 并没有降低，因为他们实际上将每个 TCP 分配给固定的工作线程，所以其任务模型并不是 shared queue 而是 multi queue 的。将 Memcached 改为 UDP 模式能够模拟 shared queue，从 7(d) 中发现了类似的优化效果。对于 Nginx，不使用 long TCP 而使用 short TCP，每次建立连接后发送 20-40 个请求，然后关闭连接，重新建立，也能够获得类似的效果。</p><p><img src="figure-7.png" alt="figure-7"></p><p>即使有了上面的这些优化，真实系统还是和模拟系统相去甚远，论文指出，真实系统中依旧会有一些 CPU 资源被用来处理网卡中断，linux 默认使用 <a href="https://linux.die.net/man/1/irqbalance">irqbalance</a> 在多核设备中分配处理中断的 CPU。在负载较低时，irqbalance 会将中断分配给一个固定的核来处理（节能模式）；但是在负载高时，irqbalance 会将中断以负载均衡的方式分配给多个核，尝试让不同核的负载相等。因此在真实系统的测试中，worker 进程常常遇到这种中断。这种终端会造成两个后果，一是会减少 worker 处理任务的时间，破坏缓存，二是会破坏 FIFO 策略，这里我不是特别理解，猜测是这样，网卡先后收到 A 和 B 两个请求，按照 FIFO 顺序，应该是先处理 A 再处理 B，但如果 A 是 core 1 处理的，B 是 core 2 处理的，插入到 shared queue 中的顺序就可能是先 B 后 A，导致局部不能完全使用 FIFO 策略。解决方法也很简单，用一个单独的核来处理网络中断，其他核处理请求不发生这种中断。Figure 8 是使用这一策略后的效果。但是减少一个处理请求的核也意味着吞吐的降低，理想情况下，使用这一优化策略需要让处理终端的核跑满。对于 Memcached 来说，处理网络线程与处理请求线程的数量大约是 1:3。但是个人感觉这种做法在生产上很难用，一个复杂系统往往要调整多个线程池的大小，难以让所有的线程池都正好把自己跑满（而且 workload 的负载情况可能会随时间变化）。论文里对这个优化在生产上提出的展望是在毫秒级的时间里线程数量不变，在分钟级的时间里，会根据系统的整体情况调整线程数，挺好的。</p><p><img src="figure-8.png" alt="figure-8"></p><p>现在处理器往往支持 NUMA 架构，NUMA node 之间的通信成本较高，这也会给应用设计带来变化。Linux 默认的内存分配策略是先从一个 NUMA node 进行分配，直到这个 node 分配完之后再去另一个 node 分配，这会造成跨 NUMA node 的内存访问，影响性能。解决方法也很简单，在每个 NUMA node 上部署一个服务。Figure 9 是这个优化的效果，简单有效。</p><p><img src="figure-9.png" alt="figure-9"></p><p>在服务器负载低的时候，服务器节能策略会自动启动，操作系统通过将 CPU 置为 C-state 来停止一些 CPU 循环，当 CPU 被设置为 C3 时，需要花费 200ms 来唤醒。同时，操作系统还会动态调整 CPU 的时钟频率（图中 scaling），Figure 10 是关闭这些节能设置的测试结果。</p><p><img src="figure-10.png" alt="figure-10"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>降低尾延迟是一件水滴石穿的工作，将各方面的细节反复打磨，尾延迟的优化空间是非常大的。</p>]]></content:encoded>
      
      
      
      
      <comments>https://blog.tongmu.me/2022/05/22/Tales-of-the-tail/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Summer Pocker RB 的杂谈</title>
      <link>https://blog.tongmu.me/2022/04/05/Summer-Pocket-RB/</link>
      <guid>https://blog.tongmu.me/2022/04/05/Summer-Pocket-RB/</guid>
      <pubDate>Tue, 05 Apr 2022 23:56:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://bangumi.tv/subject/295957">Summer Pockets -REFLECTION BLUE-</a>（之后会把 REFLECTION BLUE 简称为 RB）这游戏从年前玩到年后，游戏记录甚至已经超过了 100h，当然这有开着游戏去做其他事、以及打原文推进速度较慢的原因，但也和这游戏节奏缓慢脱不了关系。先给个总分 7.5 吧，后面详细说原因。</p><p><img src="./sprb-clear.jpg"></p><h2 id="游戏分支"><a href="#游戏分支" class="headerlink" title="游戏分支"></a>游戏分支</h2><p>这个游戏各个 End 都很不错，单论某条线没有什么很大的毛病可以挑，但也都存在塞日常撑篇幅的问题，要问我每条线印象还剩多少，大概也就剩下最后故事高潮的那几个小故事了，这里的问题虽然比较大，但还不是最致命的。这个游戏给我体感最不好的地方在于线路的割裂，RB 是后续加入 DLC 的版本，三条线单独看都还不错，但和故事的 TE 关联性都不强，这里强调一下 TE 不需要打这三条线也能进，像我这样打完七条线最后进的 TE，体验就不是很好。</p><p>这个游戏的不同分支带给我的感觉就是割裂，虽然是围绕同一个世界观的展开，但是剧情的割裂感十足，少年团的几位出镜率还不错，到紬、静久和鷗，不是自己的线就直接人都见不到了。这个割裂感导致我像是在玩 n 个游戏，每个游戏都有那些让我有些昏昏欲睡的日常，在游戏进入高潮前，缺少勾起玩家好奇心的点，就只能看作者不停的在做铺垫。因为这个游戏整体性不是很好，再给一份每条线的评分：</p><ul><li>しろは 7.5</li><li>蒼 7.5</li><li>鷗 8.5</li><li>紬 7.5</li><li>静久(RB) 8</li><li>野美希(RB) 8</li><li>識(RB) 9</li><li>うみ(RB) 8.5</li><li>TE 9</li></ul><p>RB 新增的线在我这里印象都还挺好的，但是因为割裂感的问题，我觉得没有将作品整体的分数抬起来，如果再让我选一次，我可能会选择原版不带 RB 的三条线更快的进 TE（也更省钱）。</p><p>当然这个游戏也有很多好的地方，但是很难不剧透说出来。</p><h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2><p>虽然我对着这游戏的整体构成一顿喷，但每个小故事又都有吸引我的地方，所以我慢慢的把这个游戏给打完了。</p><p>家庭的温馨是这个游戏里很重要的成分，游戏花了很多的篇幅来做铺垫，虽然有些啰嗦，但不到扣分的程度。玩这个游戏是很容易勾起一些小时候的回忆的，怀念年复一年的悠长的暑假。</p><details><summary>以下剧透</summary><p>在野美希、うみ和 TE 三条线里家庭是三种气氛，野美希最后接受现实、接受大家的关怀；うみ被破防后治愈；TE 里过家家过成一家人</p></details><p>这个游戏的剧情量庞大，而所有的故事都发生在一个小岛上玩到后期难免有些让人疲倦，大部分故事发生的场景，在开场就已经给你摊牌了，而一路玩到 TE 的过程中又基本没怎么出现新的场景，感觉 Key 社可以把这游戏做的再豪华一点的…</p><p>我很喜欢鷗线讲的故事，大冒险真的很有趣，最后得到了儿时“玩伴”的回应是很戏剧的好结局了，而我觉得新島夕不妨把刀发的更直接一些，再把眼光放得更远一些，看看 Atri 是怎么处理这种结局的。</p><p>论单线来说，識线的质量看起来是最高的，很不错也很完整的故事，解释了游戏中的很多设定，可惜的是没有把其他线之中的现世与过去连结起来。阴阳两隔的对话，是奇迹还是思念？</p><p>给静久线 8 分是因为我个人很喜欢这个结局，但是这线的剧情有点拉跨，我希望能在其中看到像在紬线一样的挣扎，可惜没有施展开拳脚。</p><p>其他线不来评价了，感觉不是很值得说…</p><p>这个游戏整体的感觉是把夏日的漫长感给刻画出来了，但是缺少一点悠远的味道，这个夏日过去了，主角和我们还剩下什么，留下一些刻骨铭心的回忆，如果能做出这个感觉来，想必也不会塞那么多日常戏了。也是因为缺少了这个感觉，我觉得这本游戏给我留下的感觉不能伴随我度过太漫长的岁月。</p><details><summary>以下剧透</summary><p>感觉这个游戏在扯出 TE 的设定以后自己没有控制住剧情，因为新元素过多，方向盘握不住了，只好一脚刹车，刹住感情高潮了。这里面有太多没来得及解释的东西，比如鳴瀬しろは的母亲和鏡子的故事，鳴瀬しろは和主角再一次相遇的故事等。我在 TE 中所期待的是酣畅淋漓的情感宣泄，可是这一脚刹车让感情收住了，把前面几十个小时所铺垫的感情给收住了，可惜可惜。</p></details><h2 id="杂谈"><a href="#杂谈" class="headerlink" title="杂谈"></a>杂谈</h2><p>因为花了很多时间打这本游戏吧，同样的时间差不多能看掉四五十本电影或者十几二十几部番剧了。所以还是希望这种题材的作品能珍惜玩家的时间，我们仔细阅读每一句台本，不是来看这些怎么样都好的日常的。</p><p>在打通之后，我马上打开了搁置已久的<a href="https://bangumi.tv/subject/205373">ファタモルガーナの館</a>，真实的感受到了在感情渲染上的差距，本身 TE 应该是整个游戏情感达到最高潮的部分，但 Summer Pocker RB 剧本在语言上的冲击力远不及 ファタモルガーナの館，直观感受是脚本缺少锤炼吧。</p><p>看有的旮旯 game 排名，Summer Pocker RB 很高啊… 让我来评可能就得滑铁卢了，整体不过不失，雲龍寺魁是很有潜力的脚本作者，期待未来更好的发挥。</p>]]></content:encoded>
      
      
      
      
      <comments>https://blog.tongmu.me/2022/04/05/Summer-Pocket-RB/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>从荒芜到丰饶的大海 - VLDB Summer School 2021 小记</title>
      <link>https://blog.tongmu.me/2022/01/25/VLDB-Summer-School-2021-notes/</link>
      <guid>https://blog.tongmu.me/2022/01/25/VLDB-Summer-School-2021-notes/</guid>
      <pubDate>Tue, 25 Jan 2022 15:43:53 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近有在海口幸亲临现场参加了 VLDB Summer School 2021，见到了不少（未来的）业内大佬，也蹭了四个上午的课程，感触良多，这里写一点我个人对未来的看法，所谈及的东西或与本次活动主题分布式事务有关、或是数据库相关的其他方面。这是一篇吹牛的文章，没啥参考价值，大家随便看看即可。</p><h2 id="活动回顾"><a href="#活动回顾" class="headerlink" title="活动回顾"></a>活动回顾</h2><p>于向遥老师的课很好，课件里的内容覆盖了事务处理的大部分重要研究成果，于老师讲课也是娓娓道来，听完之后我感觉下午上台的压力很大。于老师讲了四部分，我听前两节课也当是补了补课，在工业界混久了，对一些基础内容的理解就变得模糊了，而因为对这些基础理论的疏忽，读一些文章，比如 Silo, TicToc 这种，就没有一个顺理成章的思路，这次换个方向去理解这些文章、增加的假设、方法论上的变量控制，深有感触。于老师的后两堂课就比较 high level 了，Cloud Native DB 我也不怎么懂，还有不少没听明白的地方，需要回去补补课的（Aurora 自己也没有把所有的技术细节公开）。在我看来，Aurora 这种架构的优势在于小规模用户，以相对低的成本（但是 Amazon 卖的并不便宜）获得小规模上的高性能服务；而一旦选择 NewSQL 路线，竞争优势则不在于这种规模下的单 TPS 费用（不过听说有 NewSQL 数据库单机能跑过 MySQL 还是很震撼的），InnoDB 与云盘的结合也是个有意思的话题，我不是专家就不过多展开了。最后一节课的 Deterministic 数据库我事前也专门研究过，当时和一些工业界的朋友讨论的结果就是因为这种技术的限制过多，所以暂时不大能想到合理的使用场景，不过这项技术的思路是很有意思的，越到下层的 log 越大，所以只要下层能有确定性的结果，将副本复制提前，就会有更大的优化空间。在课后提问时有人问了副本之间的追赶问题，这确实是我之前没有考虑到的缺陷，在传统的搭建在单机存储引擎之上的副本复制协议之间，当某个节点落后太多时，可以通过发送 snapshot 来快速追赶，但是在确定性数据库里，这种技术可能会有问题，因为他需要一个全局 sequencer，而让全局 sequencer 去发送一个很大的 snapshot 就可能让整个系统卡住。用广义的眼光来看，在单机引擎上加上 Raft/Paxos 和他们的日志引擎，也能看作一个确定性数据库。</p><p>英俊哥哥讲课的时候同事有急事找我，没有听到，很可惜，回头对着录像补补课，这里就不展开说了。不过英俊哥哥宣传的 <a href="https://github.com/risinglightdb/risinglight">RisingLight</a> 项目我非常感兴趣，抓住机会跟迟老师学习。</p><p>魏星达老师的课我很喜欢，也是内容很扎实的课，我不大懂新硬件，但也在一些论文中看到过 HTM 和 RDMA 的优化，不过我所读的论文一般将这部分放在 future work 里面，所以之前对细节还不甚了解。数据库从内存模型学习了很多概念与技术，尤其是在一致性上，对于不同的一致性模型，我们往往也能够在内存操作之上找到对应的概念，而 HTM 将一些事务的特性反带到内存模型当中，配合上 RDMA，让内存模型与事务模型更好的对等起来。这个思路非常精彩，IPADS 围绕新硬件做的一系列研究可能会成为下一代数据库的技术基石。当然对于这些技术我还有一个很关心的点在于他们什么时候能够成为一种标准，云厂商像提供 s3 一样提供这些设备，这个想法短期内是看不到什么希望，但愿未来有一天我们能够享受这种便利。</p><h2 id="我读论文"><a href="#我读论文" class="headerlink" title="我读论文"></a>我读论文</h2><p>我读过的论文并不算多，而且是带着工程思维去读的，以前总抱着一种寻找银弹的心态在读，想着能不能在这篇论文里找到一些革命性的变更。读到后来，在某次论文分享直播时，有弹幕问了我一个问题 “你们 TiDB 里有用什么比较新的论文技术吗？”，确实把我问住了。现在来看，我们也在尽力的思考如何优化系统，但最后却和一部分学术研究擦肩而过。这里面也有很多原因，比如我们的架构设计与学术研究的方向并不是很吻合，存算分离固然给系统带来了极大的可扩展性和未来的想象空间，但也势必在性能有所损失，以及在优化上有限制。</p><p>所以现在读论文，多少会带着些批判的眼光去看，不只是看他好在哪，还会看他的 worst case 和所给出的假设能不能接受，比如一个需要存储过程的系统，在学术里是很常见的，在工业中如果加入这个假设，那就会失去一大批用户。</p><p>所以综合我读论文的一些经历，个人认为学术如何被工业界接受是一个需要思考的问题，这次活动有位老师说 Google 与 Facebook 对 researcher 的要求之一都是需要说服工程部门采纳，我觉得很好，当然当下不被采纳的研究成果也是很有价值的，这两个方向都需要有人研究。</p><h2 id="Bottom-up-Design"><a href="#Bottom-up-Design" class="headerlink" title="Bottom-up Design"></a>Bottom-up Design</h2><p>这是同事分享的观点，我觉得很好，所以把核心思想在这里也分享一下，学术中追求的是创新点，但工业界不是。我们所做的很多优化，其实并没有架构上的改进，例如在当今磁盘设备的速度越来越快时，以往大家认为瓶颈都在 IO 设备之上，所以尽力优化写盘的次数，但是当 IO 设备不再是一个性能瓶颈时，我们去提升系统性能的思路也需要随之改变，比如当硬盘能过提供比较大的 iodepth、拥有越来越好的随机读写性能时，我们的系统也需要随之优化。我们研究事务，如果忽视了底层的特性，在不是瓶颈的点上做了优化的工作，最后可能不能够得到满意的结果。</p><h2 id="复杂系统"><a href="#复杂系统" class="headerlink" title="复杂系统"></a>复杂系统</h2><p>在一个复杂系统中，工程能力是非常重要的，在这次活动里，我看到很多同学在实现 Percolator 时遇到了困难。Percolator 的原理其实并不复杂，我相信大家都能说清楚，但如果加入了接口幂等性的要求，就变得难以想清楚了，一些 corner cases 的处理要求在写代码的时候能想到某些特定的时序，再加上需要操作多个 Column Family 以及考虑 MVCC，这个模型的实现就变的复杂起来了。</p><p>说这个的时候就想起了当时和同事一起尝试在 TiDB 里做 Aria 的实现（由于理解不正确，当时实现的很挫，也有不少错误），这实在是一件苦差事，尤其是我们最后为了让 TPC-C 能跑起来处理了许多 bug。</p><p>在一个复杂系统中，应用研究成果会有很多的限制，比如我看到的很多论文在事务性能优化上都做得很好，但是大部分时候却不提及 DML 与 DDL 并行的问题，但是 DDL 确实是一个工业界的大问题，即使有了 F1 Online Schema Change，实现流派也有好多种，也各有长处，如果能看到一些这种方面的研究，也是一件很令人开心的事。</p><p>有一个工作这次大家都没有谈及，但是是我个人觉得既有意思又重要的——测试。我之前专门做过一次事务测试的 talk，在我看来这个东西难做也难讲，但很多时候（事务）测试并不比代码实现简单。今天我们对事务在隔离性和一致性上都已经有了相对明确的定义，但这还未能完全与现实的系统对应起来，比如有 DDL 参与的情况下什么表现才是符合预期的，就是一个难以回答的问题了。这方面我觉得 <a href="https://github.com/jepsen-io/elle">elle</a> 做了非常杰出的工作，但回过头来想他的思路也是 <a href="https://github.com/jepsen-io/jepsen">jepsen</a> 这方面日积月累、水到渠成的结果，个人觉得 elle 目前的缺陷可能在于用于推算事务关系的结构体与真实场景不太一样，以及与 SQL 语义的兼容性不是非常好。</p><h2 id="杂谈"><a href="#杂谈" class="headerlink" title="杂谈"></a>杂谈</h2><p>去现场活动是一件很开心的事情，上台面对这么多优秀学生是件很让人激动的事，我之前虽然做了一系列的 talk，但都是线上直播，所以自然在氛围感上差点意思。这次发现有这么多同学听过自己的 talk 也令我意外和惊喜。我们这个领域的高速发展离不开开源精神，在知识分享上我秉持相同的态度，没有什么值得藏的。</p><p>最后聊一下本文的题目，前面说的都是一些个人实际的想法，而这个题目的话题我不敢说的太大声，所以在文末来小声聊聊。借用于老师上课所引用的一句话 “Are we polishing a round ball?”，这个说法很好，我们不知道自己是否处于空洞的丰饶海还是一片无边无际又值得探索暖海之中。本多繁邦寻找了一辈子的清显转世，最后发现自己所追求的却是一片空洞。</p>]]></content:encoded>
      
      
      
      
      <comments>https://blog.tongmu.me/2022/01/25/VLDB-Summer-School-2021-notes/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>西藏漫游指南 - 经验篇</title>
      <link>https://blog.tongmu.me/2021/07/24/guide-to-the-tibet-1/</link>
      <guid>https://blog.tongmu.me/2021/07/24/guide-to-the-tibet-1/</guid>
      <pubDate>Sat, 24 Jul 2021 15:08:50 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>2021/06/17-2021/06/24，在西藏进行了为期一周的旅行。我将从经验和记录两个方面来讲述在这一次旅行，希望能够给想要去西藏的同学们一些帮助，同时分享一些拍到的好图和经历过的有趣的事。</p><p><img src="everest-ticket.jpg" alt="everest ticket"></p><h1 id="经验篇"><a href="#经验篇" class="headerlink" title="经验篇"></a>经验篇</h1><h2 id="高原反应"><a href="#高原反应" class="headerlink" title="高原反应"></a>高原反应</h2><p>重点地区海拔</p><ul><li>林芝，3100m</li><li>拉萨，3600m</li><li>日喀则，3800m</li><li>羊湖，4400m</li><li>珠峰大本营，4900m</li><li>阿里地区，平均 4500m</li></ul><p>高原反应因人而异，我们五人同行最后都成功在珠峰大本营过夜，也从群友那边听说了不少失败案例，从扛不住到抬下来住院都有。在这一点上最好放平心态，没有必要觉得上高原就会性命攸关，至少人在拉萨顶不住了，能让你吸着氧下来。</p><p>第一天过去不能洗澡，这个应该旅店老板都会提醒，几乎所有的旅游攻略也会讲。</p><p>高原反应一般不会突发，我在下飞机的时候活蹦乱跳，直到当天晚上才开始出现轻微症状（头晕），应急药物可以在拉萨购买，那边药店非常多。</p><p>有条件的同学可以关注心率和血氧这两个指标，刚去时心率会明显上升，我上升到了 110-120 之间。</p><p>一般去珠峰大本营过夜之后，高原反应就会消失，经过海拔 4900 米的锻炼，你的身体已经是高原的形状了！</p><p>在高海拔的情况下继续上升是一种挑战，一般去珠峰前一天都会在日喀则进行休整，日喀则的海拔是 3800m。我们的路线是 拉萨-羊湖-日喀则-珠峰大本营，上珠峰大本营的感受比较类似从拉萨到羊湖。如果从拉萨到羊湖没有很严重的反应（去羊湖会越过五千米的高山，可以在山顶拍照并感受一下身体状况），那么去大本营的问题也不大。</p><p>要买什么药物、多少氧气，这点请自行判断，我们按照每人一罐（35 元）的额度准备去珠峰大本营的氧气，最后剩下了一半多。如果状态好，在珠峰大本营并不需要吸氧。另外上面有 800 元吸一晚的服务，不需要过于紧张。</p><p>最后说一点克服高反的经验，高反是可以克服和适应的，如果没有严重到卧床不起的程度，就尽量少吸氧、尽量出去玩，活动一天之后往往状态都会变好。</p><h2 id="路线"><a href="#路线" class="headerlink" title="路线"></a>路线</h2><p>常见的旅行路线有三条。</p><ul><li>拉萨-林芝，1 周</li><li>拉萨-羊湖/纳木错湖-珠峰，1 周</li><li>拉萨-珠峰-阿里，2 周</li></ul><p>在拉萨高原反应严重的同学，可以考虑第一条路线，林芝海拔三千出头，和青海湖相近，绝大部分人都没有问题。</p><p>如果在拉萨反应不大，在羊湖也可以坚持，那么可以考虑珠峰路线，至于平均海拔 4500m 的阿里，从珠峰下来后应该也是可以坚持住的。</p><h2 id="珠峰"><a href="#珠峰" class="headerlink" title="珠峰"></a>珠峰</h2><p>世界最高峰是西藏最独特的景点之一，自然也有许多人担心高原反应和紫外线的问题，我在珠峰也见到不少氧气不能停的游客。</p><p>来到珠峰的人普遍都很兴奋、很亲和，我们穿上毕业服被人一路打招呼。大概也能理解这种情怀吧，能跑到这种地方来的，又有几个正常人呢？当感受到我们都是大自然前的蚂蚁时，自然也会对彼此多些友善。</p><p>珠峰前有一片拍照用的石子路广场，肯定有许多人在那排队和石碑合照的，日落时分的风很大，穿好衣服可以拍落日的延时，运气好能看到珠峰金顶。</p><h2 id="摄影指南"><a href="#摄影指南" class="headerlink" title="摄影指南"></a>摄影指南</h2><p>我的 sd 卡在回来前一天，拷数据的过程中损坏了。虽然在写这篇文章的时候，我已经恢复好了里面的数据，但丢数据还是挺慌的。</p><p><strong>如果相机支持，建议多插张卡开启双写。</strong></p><p>在西藏摄影也是件看脸的事情，我们在拉萨的两天天气相对较好，从去日喀则开始，白天的云很厚。在上珠峰和离开珠峰的时候，都没能在<a href="http://www.dili360.com/cng/article/p5923d59753f0148.htm">加乌拉山口</a>（珠峰门票上的）看到五连雪山。</p><p>高原气候会加剧体力消耗，尤其是某些重量级长焦，在离开拉萨去羊湖，登上 5000 米观景台时，我就因此累出高反。</p><p>带三脚架，不管是星空、日出日落，在西藏拍延时绝对是最容易出片的方案之一。</p><p>多带一块电池，如果没有住正经宾馆（比如珠峰住帐篷）的话，可能做不到每晚充电。</p><p>西藏夜晚天气变化极大，尤其是 6 月底进入雨季之后，可能十二点还乌云密闭，三四点就漫天繁星了，如果想拍星空，建议每个小时起来看一眼天气（或者四五月进藏），辛苦一下不后悔。</p><h2 id="星空"><a href="#星空" class="headerlink" title="星空"></a>星空</h2><p>西藏几乎没有光污染，再加上空气稀薄，观测星空的效果相当好，需要考虑的困难有：</p><ul><li>云</li><li>路灯</li><li>过路车</li></ul><p>西藏的旅游旺季从六月开始，七八月达到高潮，但是雨季带来的影响使得云成为了星空观赏和摄影的困难，这点只能靠脸和熬夜等待。</p><p>路灯不仅是光污染，对地景的影响更大，如果愿意熬到后半夜，路灯会关闭。</p><p>过路车是通宵开不停的！我们在羊湖时住在湖边帐篷里，听了一夜泥头车的呼啸声。但是珠峰大本营没有车半夜开的，可以尽情拍摄。</p><h2 id="保暖"><a href="#保暖" class="headerlink" title="保暖"></a>保暖</h2><p>这里以六月的气温来说明，在拉萨，短袖加外套（防晒）就可以了，虽然很热，但是不会出很多汗。</p><p>但是西藏的半夜很冷，如果要拍星空的话，一定要穿上羽绒服和秋裤。在珠峰大本营时，两侧高山夹住远处的珠峰，形成了天然的风道，风大到能吹动三脚架。</p><h2 id="防晒"><a href="#防晒" class="headerlink" title="防晒"></a>防晒</h2><p>回来后觉得这个问题是事先多虑了，西藏地广人稀，在出了拉萨之后，一天的大部分时间都在车里，根本没多少机会晒到太阳。</p><h2 id="边防证"><a href="#边防证" class="headerlink" title="边防证"></a>边防证</h2><p>边防证是一个很简单的证件，十分钟左右即可，但是需要在户籍所在地办理，否则需要居住证。在不方便本地办理的情况下，某些地区提供了远程办理后邮寄的服务，只需要网上申请即可。边防证也可以在拉萨用身份证办理，但是需要给当地旅行社交钱。</p>]]></content:encoded>
      
      
      
      
      <comments>https://blog.tongmu.me/2021/07/24/guide-to-the-tibet-1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>学日语要花费多少心思系列</title>
      <link>https://blog.tongmu.me/2021/07/06/learning-japanese/</link>
      <guid>https://blog.tongmu.me/2021/07/06/learning-japanese/</guid>
      <pubDate>Tue, 06 Jul 2021 16:08:02 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>这一系列文章对我学习日语过程的记录，包括了从初级到 N1 考试，以及之后的学习心得，希望对大家有参考价值。</p><ul><li><a href="/2021/04/04/learning-japanese-1/">学日语要花费多少心思（一）</a></li><li><a href="/2021/04/07/learning-japanese-2/">学日语要花费多少心思（二）</a></li><li><a href="/2021/04/11/learning-japanese-3/">学日语要花费多少心思（三）</a></li><li><a href="/2021/07/06/learning-japanese-4/">学日语要花费多少心思（四）</a></li><li><a href="/2021/07/06/learning-japanese-5/">学日语要花费多少心思（五）</a></li></ul>]]></content:encoded>
      
      
      
      <category domain="https://blog.tongmu.me/tags/%E6%97%A5%E8%AF%AD%E5%AD%A6%E4%B9%A0/">日语学习</category>
      
      
      <comments>https://blog.tongmu.me/2021/07/06/learning-japanese/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>学日语要花费多少心思（五）</title>
      <link>https://blog.tongmu.me/2021/07/06/learning-japanese-5/</link>
      <guid>https://blog.tongmu.me/2021/07/06/learning-japanese-5/</guid>
      <pubDate>Tue, 06 Jul 2021 16:04:01 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>这篇文章写于参加 2021 年 7 月的 N1 考试之后，谈一谈心得。我个人的心得不一定适合所有人，参考时请结合自身情况。</p><p>JLPT 考试是有公开例题的，准备考试的第一步可以通过做例题来熟悉题型：<a href="https://www.jlpt.jp/e/samples/forlearners.html">https://www.jlpt.jp/e/samples/forlearners.html</a></p><h2 id="词汇"><a href="#词汇" class="headerlink" title="词汇"></a>词汇</h2><p>词汇是我最头疼的地方，因为不会的就是不会，生词四选一的时候只能猜，而近义词辨析我连语文课上中文的都做不好，还要做对日文的，要求也太高了。里面还有一些敬语和排序题的语法题，全凭语感瞎猜。但即使如此「しょんぼり」这个词汇，是我在 <a href="https://bangumi.tv/subject/4124">Q 娃追心</a> 里学到的，这次的 N1 考到了。</p><p>汉字的读音题，做多了会有感觉，猜的正确率也会变高，里面经常会出现我没见过的汉字词，但是有的选项一眼看去就是错的。</p><p>关于其他类型的词汇题，似乎没有太多好说的，总之做的快一点就好了，阅读题很杀时间，我的时间分配是 30 分钟给词汇，剩下 80 分钟给阅读。</p><h2 id="阅读"><a href="#阅读" class="headerlink" title="阅读"></a>阅读</h2><p>我看过所谓的阅读技巧，不能说没有用，但根据关键句来做题的前提是找对关键句，而我练习时大多出错的原因也在于找不准关键句，所以在实际考试中我采用了自己的做题方式。</p><p>首先看第一题的题干，不看选项。不看选项原因有两个，一是时间原因，读文章前后看两轮选项会花费更多的时间；二是选项干扰，看了选项之后，读文章的过程中容易约束自己对文章的理解。看了问题之后读文章，自己思考这个问题的答案，读文章不要急慢慢来，一定要完全理解，不能摸棱两可。在最初练习的时候，我是做不到完全理解文章的，需要结合很多自己的猜测，在精读了一些阅读文章之后，不知道为什么就能够做到慢慢读并且读懂了。一般来说，第一个问题的答案就在前几段，所以当找到答案之后就可以去看选项了，然后看下一个问题的题干、继续读文章。最重要的，是能够看懂整篇文章，而不是执着于寻找关键句。</p><p>我在练习阅读时候是这么做的：</p><ul><li>正常做、对答案</li><li>看答案中指出的关键句，把这些句子弄懂</li><li>重新读整篇文章、查里面所有的语法和生词，直到完全看懂这篇文章</li></ul><p>前期这么练习的速度很慢，所以我的练习量也不大，在考试前一天，飞机上，我就拿着往年试卷在读文章，那时候已经觉得做阅读比较轻松了。学外语都会遇到阅读文章困难的问题，比如看了后面忘了前面，这点如何克服，我也说不清，可能只能靠爱了吧。</p><h2 id="听力"><a href="#听力" class="headerlink" title="听力"></a>听力</h2><p>听力要多练，大概可以分为泛听和精听两种。</p><p>对于泛听，看番看剧都能够当作练习材料，最好看无字幕版，因为字幕会让你放弃听觉，能找到字幕对比版的话更好，听不懂的时候直接翻出来看（因为番剧中真的有很多莫名其妙的片假名词）。泛听最好选取自己喜欢的题材，比如我最近在学习游戏王，就把初代游戏王翻出来看了，这个番把「しか」用的出神入化（例：この状況を応対するカードは一枚しかない。能应对这种情况的卡牌只有一张。），听习惯了以后就不觉得这种表达方式复杂了。</p><p>我也试过拿「半澤直樹」来练习，结果是惨败，除非我一句话听三遍并且一直查辞典，不然根本跟不上台词。但是这么看剧的话，就失去乐趣了啊。</p><p>精听的话，有人建议听写 NHK 新闻的，但是 NHK 新闻真的很难，而且一条一分钟新闻的新闻可能出现好几个大臣的名字，能听写的话你的听力水平已经远超 N1 了。所以我还是推荐用 N1 原题，做一遍，然后看听力原文，看完之后再听，直到完全听懂。</p><p>直到考试时，听力我也没练的好，而且听力和临场状态关系很大，建议放平心态。</p><h2 id="关于-JLPT-考试"><a href="#关于-JLPT-考试" class="headerlink" title="关于 JLPT 考试"></a>关于 JLPT 考试</h2><p>JLPT 考试只是日语学习的敲门砖，考了 N1 之后才意识到这个考试其实没有在难为考生，比如在听力题里，所有选项中的汉字都有注音，生怕你听到了对不上。如果你是一个读了很多日文书或者能够完全看懂日文游戏里台词的人，那么看几套真题练练手，就可以上考场了。</p>]]></content:encoded>
      
      
      
      <category domain="https://blog.tongmu.me/tags/%E6%97%A5%E8%AF%AD%E5%AD%A6%E4%B9%A0/">日语学习</category>
      
      
      <comments>https://blog.tongmu.me/2021/07/06/learning-japanese-5/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>学日语要花费多少心思（四）</title>
      <link>https://blog.tongmu.me/2021/07/06/learning-japanese-4/</link>
      <guid>https://blog.tongmu.me/2021/07/06/learning-japanese-4/</guid>
      <pubDate>Tue, 06 Jul 2021 12:31:42 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>这篇说一说词汇方面的应试或是做题。</p><p>我学的很辛苦，但是发现一做题就错（我做的是红蓝宝书），「しゅ」、「しゅう」、「しょ」、「しょう」完全分不清，想要通过平常的积累把这些东西理清楚，是很困难的，这里非常忌讳摸棱两可的记法。事实上就算是汉语，如果没经历过语文考试的训练，也有不少字是会念错音的。但如果是以考试为目的的话，当然有对策。一个汉字的读法一般是固定的或是有几种变数，考试喜欢把一些细节加以混淆，出一些很相似的读音，那么应试手段就是把近音词、多音词、同类用法的词一次记忆，然后通过题目去巩固，当然背单词表是可以的，但是效率上不能让想快速通过考试的朋友（比如我）满意。</p><p>这个方法，是我最近翻了翻老师借给我的书后想要尝试的，此前我在刷 N1 词汇表，效率和效果都不大行，而跟着这两本书从背单词的过程就给了我能解决做题困难的感觉。</p><p><img src="1.jpg" alt="两本词汇书"></p><p>我想说的并不是掌握了方法之后能够降低学习量，这是做不到的，但我想尽可能用自己的学习经历来降低一些学习过程中的，尽量减少遗忘的部分，提高学习时间的利用率，用方法来压榨自己。</p><p>在背「漢字」这本书时，我会将书中的假名盖住，自己在本子上对着中文写假名，写完后纠正，而复习的时候就会根据我写的假名把汉字想出来，如果对着假名和汉字都有的词汇去复习，大脑就会偷懒，效果不好。</p><p><img src="2.jpg" alt="漢字背诵"></p><p>我觉得「語彙」的练习更加鬼畜些，我使用的方法是把假名抄写下来，然后一遍遍的对着假名说出汉字和意思，因为重复汉字少，所以覆盖的词汇比「漢字」书里要多不少。</p><p><img src="3.jpg" alt="語彙背诵"></p><p>如果仅仅对着单词表看，容易陷入发呆的状态，或是感觉自己都记下来了，其实记得都很模糊，不经考，所以使用背诵和默写的方式来避免不可控的偷懒。</p><p>红蓝宝书写的很好，在答案里还会有不少扩展，但对于应试来说，效率不是很行，如果是以拿证为目标的话，可以考虑优先记整张试卷都有用的词汇，比如口语中常用到的。</p><p>后记：过于枯燥，我没坚持下去。</p>]]></content:encoded>
      
      
      
      <category domain="https://blog.tongmu.me/tags/%E6%97%A5%E8%AF%AD%E5%AD%A6%E4%B9%A0/">日语学习</category>
      
      
      <comments>https://blog.tongmu.me/2021/07/06/learning-japanese-4/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>毕业休假前的一点反思</title>
      <link>https://blog.tongmu.me/2021/06/06/memoria-2021-mid/</link>
      <guid>https://blog.tongmu.me/2021/06/06/memoria-2021-mid/</guid>
      <pubDate>Sun, 06 Jun 2021 00:45:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>6.5 上午，做完了确定性数据库的 meetup，感觉终于可以进入一段休假期，虽然这半年淡出了公司的活动，但也意外的做了不少事，因此做点总结和反思。这篇文章有一个读起来比较不友好的<a href="/2021/05/31/failure-proposition/">版本</a>。</p><hr><h2 id="Meetup"><a href="#Meetup" class="headerlink" title="Meetup"></a>Meetup</h2><p>挖坑是困难且需要决心的，我在完成<a href="/2021/02/01/deterministic-database-history/">这篇文章</a>时（虽然现在看这篇文章缺乏重要的细节，也有些错误的理解），就萌生了分享的想法，因为确定性数据库这个方向实在是太专业了，结果设计成了一整个系列。愿意做这件事情，一是自己学了不少东西，需要梳理，二是分享知识这件事情是能够让我感到快乐的。和 mentor 交流了想法后找到 community 的小姐姐，事情一拍即合，于是在寒假期间，那时候就可以预料到这毕业季不大安宁了。很可惜这三次 meetup 都是线上的，不能和观众面对面交流。把知识消化，然后用合理的形式展示和讲解，整个过程很是费劲，老实说我也不知道能对上电波的观众到底有多少，感谢帮忙组织 meetup 的小姐姐，把录像传到了 b 站上，让知识长久的保存下来。</p><p>三次 meetup 都组织的很费劲，我对于讲课的认知是这样的，通读相关领域重要的 paper，对比他们的方法和思想，以合适的方式串联起来。每一次分享，都不是针对一篇 paper 的解读，将类似的 paper 放在一起讲解效率会更高，对比也会让理解更加深刻，最后在此之上谈论自己的理解，我寄于 meetup 的这些想法，传达到了吗？</p><p>讲课很容易陷入自己对知识的温习节奏，从而忽略了观众的思考时间，甚至略过某些重要的细节。我觉得自己在这方面还是很不足的，只有老师这种常常站上讲台的人才能够比较好的控制节奏，因此也尊敬能够照顾学生进度的老师，这很不容易。另外我似乎对于反复讲述已经弄懂的东西这件事会产生烦躁感，做 ppt 的过程可能就会反复翻阅 paper（大概单纯花在做 ppt 上的时间会有四五天），最后根据 ppt 的内容写成文章（写文章需要三四天，直接使用之前画好的图），在写完文章之后我常会有一种再也不想见到这些东西的暴躁。</p><p>事实上上台开讲之后把精神集中在内容之上，紧张会消除掉，三次 meetup 讲下来，也能够在讲的同时腾出余裕来进行思考了（狡猾的倒一杯水，卡词的时候就来一口）。不过比较可惜的是，不知道是我讲的太差，还是中国人比较内向，还是讲的东西过于专业，我很少收到反馈，抱着分享知识的目的来做这件事的我还是很乐意和人深入聊的。如果你看到这里，并且对我在 meetup 上讲的内容有兴趣的话，欢迎来找我聊天啊。</p><p>最后说一点题外话，之前在打印毕业论文的时候，遇到了老同学，他们好像都知道我做 meetup 的事，同时也收到了很多和我的工作没有直接关系的人的关心，开心！</p><h2 id="日语学习"><a href="#日语学习" class="headerlink" title="日语学习"></a>日语学习</h2><p>以前也计划过要学习日语，但是一直做不到定时的投入时间，三天打鱼两天晒网，有点语感但实在没什么水平。</p><p>报了班学日语，也没耽误什么事（中途因为毕业论文请了很久的假，感谢老师协调进度）。这么几件事一起，搞得这几个月特别的忙，非常庆幸的是坚持过来了。</p><p>学习日语的目的是为自己以后开拓一些新的道路，想试试去日本工作。一方面是因为国内的工作环境听的见的太多，基本从本科加入社团开始就一直听闻 IT 工厂里的事，现在自己也在创业公司实习过，如果日后还要数十年工作在这个环境下，难免会觉得人生缺少了新意。另一方面，我对异国他乡的生活节奏比较感兴趣，以我的偏见来看，在国内的生活是繁忙的，都市里的风景也千篇一律，通过书籍和影视作品去扩展人生总是比不上亲身体验的，因此也将其作为一大目标。</p><p>学习日语的收获当然远不止日语本身，学习一门语言是困难且费时的，我也知道真正将这门语言学好的人下了多少功夫，不仅承受住了背单词时的枯燥，还将这些知识持久的记忆起来，这十分了不起。</p><p>现在，日语课程也接近尾声了，很怀念每天上学和放学时的悠哉游哉。关于学习过程中的一些心得，我有时候会写「<a href="/2021/04/04/learning-japanese-1/">学日语要花费多少心思</a>」这系列的文章，可以参考。</p><h2 id="毕业"><a href="#毕业" class="headerlink" title="毕业"></a>毕业</h2><p>现在想来仍然没有觉得读研是个理智的决定，当时随波逐流的就走上了这条路。好在按时入学、按时毕业，但也不得不说，地处西安限制了视野，这句话很久以前一个大我很多届在杭州创业的学长说过，直到出来实习，认识了强大的人之后才感同身受。</p><p>… 省略一些 private 的东西</p><p>说一个小插曲，我被要求补充中文的引文，当时看到了一篇上交的硕士毕业论文（唯一一篇有相关性的），思路很清晰，如果早点见到的话应该会在某些细节问题上省不少力，但是直到提交论文终稿后，我才发现这篇论文的指导老师是 IPADS 的大佬。</p><h2 id="摄影"><a href="#摄影" class="headerlink" title="摄影"></a>摄影</h2><p>这件事情非常好玩，但也有些矛盾，一方面我需要长期待在电脑前才能够好好工作；另一方面我也想拍出好照片，想出去多走走。</p><p>自我评价的话，水平肯定是有进步的，但是此前太忙了，导致难以拿出大量的时间来寻找素材，五一在嘉兴的第二天，直接在外面拍了一整天，那一天的进步很大。此前总是需要在大量的素材中筛选出寥寥几张想要修的，大部分素材都很不行。期待休假的时候能找一些好拍的地方，吐槽一下，国内的街景实在是不大上镜…</p><p>晒一张前几天拍到的火烧云，这里还有一些五月份的<a href="/2021/05/11/photography-2021-05/">作品</a>。</p><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2021-06/DSC01255-50.jpg"></p><h2 id="休假了"><a href="#休假了" class="headerlink" title="休假了"></a>休假了</h2><p>我好像可以休假了，手头剩余的工作已经不多（实际上一直处于没在工作的摸鱼状态，这些事情其实做的都比较休闲），也终于处理完毕业的琐事，可以好好备考 N1 了，时间不多，自己还很贪玩，总之先休息几天吧！（笑</p>]]></content:encoded>
      
      
      
      
      <comments>https://blog.tongmu.me/2021/06/06/memoria-2021-mid/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>失败命题</title>
      <link>https://blog.tongmu.me/2021/05/31/failure-proposition/</link>
      <guid>https://blog.tongmu.me/2021/05/31/failure-proposition/</guid>
      <pubDate>Mon, 31 May 2021 00:48:20 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>这篇文章在毕业之际写给自己，是对内心如何保持对知识渴望的探讨。</p><p>相信很多人都有过“越是学习，越是觉得自己无知”的经历，伴随着学习的过程，人会变得谦虚、在听讲时会变得更有耐心，同时也会变得更加痛苦。觉得自己强大且成功是简单的，并且在这种麻醉剂下活得轻松自在。</p><p>我将之称为“命题”，是因为一个人对待知识的态度是他的个人意见，是存在他脑海里的想象之中的，“命题是实在的图像。命题是我们所想象的实在的模型。”<sup>[▲1]</sup>也就是说，可能有人觉得全人类都是失败的，也可能有人觉得全人类都是成功的。但即使全人类都是失败的，也有人活得自信，有人因深刻的感受到了这一失败而痛苦。</p><p>所谓文明、夙愿，都不是人生来就有的。在人类拥有交流的语言之前，没有什么文明；在人类拥有思考的语言之前，也没有什么夙愿。而只有当语言能够描述，且人类意识到了这些东西之后，才将其用命题表示出来，但即使这种表示，也很可能存在不同，文明是历史，文明是社会在个体上的投影，这些看法出自不同的人，也都是合理的。</p><p>如果上帝的真理果实不是为人类所准备的，那对于遍体鳞伤的发现这是空中楼阁的人会是一种怎样的打击？“对于不可说的东西我们必须保持沉默”<sup>[▲2]</sup>，这样的结论，这对于研究逻辑学的人来说或许是满足了，但对于宇宙真相又远远不够。</p><p>在达成一个大目标之后，会有满足的情绪，但是将其作为自己人生的高峰，会陷入停滞的深渊。但是即使是罗素，在完成「数学原理」后也说“我的智力再也没从这损耗里完全恢复”，对凡人来说感到疲惫而止步不前是能够理解的。持续的超越自己，避免将某个成就刻印在自身，因此劳累一生，这算是失败吗？</p><p>在万物之中，人类又是最珍惜自己的生命的，一想到有那么多萤火般一闪而过的生命，享有万物之灵的资源却不能够去追求更多的未知，难道这不能被称之为失败吗？虽然前面说了，命题因人而异，但你读到这里的时候能否感受我所叹息的事情呢，希望不要因此影响你的心情。</p><p>想到这里，问题变成了怎样的人生才是不那么失败的，我做不到以未来的后见之明来回答这一问题，尽可能地将“感觉迷茫的话保持学习就可以了，即使是现在看来毫无用处的知识在将来肯定会发光的”这种想法付诸行动，这究竟是对迷茫的逃避，还是迷雾中的天狼星呢？半年前曾写过一篇对未来过分乐观的<a href="/2021/01/18/memoria-2020/">年度总结</a>，那就把本文当作是自身的警钟。</p><p>[▲] 节选自「逻辑哲学论」</p><p>[▲1] 4.01</p><p>[▲2] 7</p>]]></content:encoded>
      
      
      
      
      <comments>https://blog.tongmu.me/2021/05/31/failure-proposition/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>风景摄影-2021-05</title>
      <link>https://blog.tongmu.me/2021/05/11/photography-2021-05/</link>
      <guid>https://blog.tongmu.me/2021/05/11/photography-2021-05/</guid>
      <pubDate>Tue, 11 May 2021 22:05:53 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近的一些作品，我想相比之前应该有些进步了。</p><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2021-05/DSC00825-826-50.jpg"></p><p>这张照片不是用广角镜头拍的，是由两张照片合成而来，下面是原图。</p><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2021-05/DSC00825%2B826.jpg"></p><p>我觉得对于城墙这种雄伟的建筑，一个视角能表达的画幅有限，所以进行了一些尝试，结果达到了我的预期，并且一开始把合成后的图发送给同玩摄影的朋友的时候，他也没有一眼看出异样。</p><hr><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2021-05/DSC00945.jpg"></p><p>非特写静物是我最不会拍的东西，挑了好久修了这一张。</p><hr><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2021-05/DSC00946.jpg"></p><p>这张图是重修的，意图表达一些年代感。</p><hr><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2021-05/DSC00949.jpg"></p><hr><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2021-05/DSC01042.jpg"></p><hr><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2021-05/DSC01125.jpg"></p><p>果然夕阳时候的光影最适合拍摄，这张是直出，无修。</p><hr><p><img src="https://maple-blog.oss-cn-shanghai.aliyuncs.com/photography/2021-05/DSC01134.jpg"></p><p>这张也是夕阳时刻的照片，不过在调色上费了些神。</p>]]></content:encoded>
      
      
      
      
      <comments>https://blog.tongmu.me/2021/05/11/photography-2021-05/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>初めてのTiDB</title>
      <link>https://blog.tongmu.me/2021/04/12/hajimete-no-tidb/</link>
      <guid>https://blog.tongmu.me/2021/04/12/hajimete-no-tidb/</guid>
      <pubDate>Mon, 12 Apr 2021 16:30:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>このブログは僕自身の観点から、PingCAPのオフィシャルのドキュメントではありません。</p><p>TiDBエンジニアです。今回、TiDB初めての使用することについてが話します。</p><h2 id="クラスターを展開する"><a href="#クラスターを展開する" class="headerlink" title="クラスターを展開する"></a>クラスターを展開する</h2><p><a href="https://github.com/pingcap/tiup/">TiUP</a>で一番小さいのクラスターを展開することはおすすめ。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">~ » curl --proto &#x27;=https&#x27; --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh # TiUPをインストールする</span><br><span class="line">~ » tiup playground --monitor=false --tiflash=0 # クラスターを展開する</span><br><span class="line">Starting component `playground`: /home/you06/.tiup/components/playground/v1.4.1/tiup-playground --monitor=false --tiflash=0 v4.0.12</span><br><span class="line">Playground Bootstrapping...</span><br><span class="line">Start pd instance</span><br><span class="line">Start tikv instance</span><br><span class="line">Start tidb instance</span><br><span class="line">Waiting for tidb instances ready</span><br><span class="line">127.0.0.1:4000 ... Done</span><br><span class="line">CLUSTER START SUCCESSFULLY, Enjoy it ^-^</span><br></pre></td></tr></table></figure><p>そして、他のターミナルを開きて、MySQLクライアントでクラスターに接続しましょう。それから、MySQL同じに使うことができまて、試してみてください。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">~ » mysql --host 127.0.0.1 -P4000 -u root</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 4</span><br><span class="line">Server version: 5.7.25-TiDB-v4.0.12 TiDB Server (Apache License 2.0) Community Edition, MySQL 5.7 compatible</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2021, Oracle and/or its affiliates.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"></span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure><h2 id="ノードの種類"><a href="#ノードの種類" class="headerlink" title="ノードの種類"></a>ノードの種類</h2><p>クラスターの中で複数のノードはあって、TiDBやPDやTiKVやTiFlashやなど。詳しい情報を知っていることは必要ではない。</p><ul><li>TiDBは計算することを担任して、実際にデータを保有することではありません。その中でオプティマイザーとトランザクションの一部があります。</li><li>PDはターム分配することを担任して、メタデータを保有することができました。</li><li>TiKVはデータの保存するノードで、トランザクションの一部とRaftに基づくのMVCCはあります。高い可用性で、分散トランザクションをサポートするのKVデータベースです。</li><li>TiFlashは<a href="https://ja.wikipedia.org/wiki/OLAP">OLAP</a>分析しているクエリを専用するのエンジンです。TiDBと同じデータを使用することができて、データを同期は必要がありません。</li></ul><h2 id="トランザクション"><a href="#トランザクション" class="headerlink" title="トランザクション"></a>トランザクション</h2><p>トランザクションはデータベースの基本的な正しさの保証です。TiDBは二つのトランザクションのモードをサポートして、楽観トランザクションと悲観トランザクションです。その中で、悲観トランザクションはデフォルトで、<code>tidb_txn_mode</code>でセットすることができます。</p><ul><li>楽観トランザクションで複雑なトランザクションが同一のキーを書くことは許します。お先にコミットするのトランザクションが成功できて、他のトランザクションは失敗します。低い競合の場合は楽観モードが適切です。</li><li>悲観トランザクションでトランザクションがの実施中はロックを書きますから、コミットは成功することが保証することができます。高い競合の場合は楽観モードが適切です。</li></ul><p>先ずは悲観モードを試してみてましょう。テーブルを作った後で、二つのトランザクションをまとめて行って、同じデータを処理しました。画像のなかで、二番目のトランザクションはブロックしました。結果は二つのトランザクションを成功して、順番は左の次に右の。</p><p><img src="demo-pessimistic-txn.png" alt="Pessimistic Txn Demo"></p><p>それで楽観モードを試します。<code>tidb_txn_mode</code>でモードをスイッチして、二つのトランザクションは同じプライマリーキーのデータを作成しました。結果は最初のトランザクションを成功して、他のトランザクションは失敗しました。それは「first commit wins」ルールです。</p><p><img src="demo-optimistic-txn.png" alt="Optimistic Txn Demo"></p><h2 id="プロダクションの注意事項"><a href="#プロダクションの注意事項" class="headerlink" title="プロダクションの注意事項"></a>プロダクションの注意事項</h2><p>TiUPの<code>playground</code>コマンドはテスト用だけて、データの可用性と安全は保障することはない。</p><p>もし、自分でクラスターを操作したなら、TiUPの<code>cluster</code>を使ってください。もしクラウドでTiDB使ってほしいかった、Operatorで展開するおよび<a href="https://en.pingcap.com/products/tidbcloud/">TiDBクラウド</a>を使うことができます。</p><h2 id="他の質問"><a href="#他の質問" class="headerlink" title="他の質問"></a>他の質問</h2><p>もし他の質問があるなら、僕にメートルおよびメッセージを送りましょう。</p><ul><li>メートル：tongmu#pingcap.com</li><li>ツイッター：<a href="https://twitter.com/you06v">you06v</a></li></ul>]]></content:encoded>
      
      
      
      <category domain="https://blog.tongmu.me/tags/%E6%97%A5%E8%AF%AD/">日语</category>
      
      <category domain="https://blog.tongmu.me/tags/TiDB/">TiDB</category>
      
      
      <comments>https://blog.tongmu.me/2021/04/12/hajimete-no-tidb/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
